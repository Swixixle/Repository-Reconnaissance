
--- FILE: README.md ---
L1: # Program Totality Analyzer
L2: 
L3: A static-artifact-anchored analysis tool that generates technical dossiers for software projects. It extracts what a system is, how to run it, what it needs, and what it cannot determine — with every claim citing `file:line` evidence backed by SHA-256 snippet hashes.
L4: 
L5: **Scope limitation:** PTA analyzes static artifacts only (source files, config, lockfiles). It does not observe runtime behavior, prove correctness, or guarantee security. Claims labeled VERIFIED mean "anchored to a hash-verified source snippet," not "proven true at runtime."
L6: 
L7: ## What It Does
L8: 
L9: Given a software project (GitHub repo, local folder, or Replit workspace), the analyzer produces:
L10: 
L11: | File | Contents |
L12: |------|----------|
L13: | `target_howto.json` | Operator manual: prerequisites, install steps, config, dev/prod run commands, Replit execution profile |
L14: | `claims.json` | Verifiable claims about the system, each with file:line evidence and confidence scores |
L15: | `coverage.json` | Scan metadata: files scanned, files skipped, Replit detection evidence |
L16: | `replit_profile.json` | Replit-specific: port binding, secrets, external APIs, observability (only in Replit mode) |
L17: | `DOSSIER.md` | Human-readable markdown dossier summarizing all findings |
L18: | `index.json` | Full file index of scanned files |
L19: | `packs/` | Evidence packs (docs, config, code, ops) used during analysis |
L20: 
L21: ## Install
L22: 
L23: ```bash
L24: pip install -e .
L25: ```
L26: 
L27: This registers the `pta` command. Alternatively, run as a module or directly:
L28: 
L29: ```bash
L30: python -m server.analyzer.src --help
L31: python server/analyzer/analyzer_cli.py --help
L32: ```
L33: 
L34: ### Dependencies
L35: 
L36: - Python 3.11+
L37: - Required packages: `typer`, `rich`, `openai`, `gitpython`, `jsonschema`, `python-dotenv`, `pydantic`
L38: 
L39: ## Usage
L40: 
L41: ### Three Modes
L42: 
L43: **GitHub repository:**
L44: ```bash
L45: pta analyze https://github.com/user/repo -o ./output
L46: ```
L47: 
L48: **Local folder:**
L49: ```bash
L50: pta analyze ./path/to/project -o ./output
L51: ```
L52: 
L53: **Replit workspace (run from inside the workspace):**
L54: ```bash
L55: pta analyze --replit -o ./output
L56: ```
L57: 
L58: ### Deterministic Mode (`--no-llm`)
L59: 
L60: Skip all LLM calls and produce only deterministic, structurally-extracted outputs:
L61: 
L62: ```bash
L63: pta analyze --replit --no-llm -o ./output
L64: ```
L65: 
L66: This mode requires no API keys and produces reproducible results. It extracts:
L67: - Package scripts (dev, build, start)
L68: - Lockfile-based install commands
L69: - Environment variable references (names only, never values)
L70: - Port binding configuration
L71: - External API usage
L72: - Replit platform detection
L73: 
L74: ### With LLM Analysis
L75: 
L76: For semantic analysis (architecture understanding, risk assessment, integration patterns):
L77: 
L78: ```bash
L79: pta analyze --replit -o ./output
L80: ```
L81: 
L82: Requires `AI_INTEGRATIONS_OPENAI_API_KEY` and `AI_INTEGRATIONS_OPENAI_BASE_URL` environment variables.
L83: 
L84: ### Scoping a Subdirectory
L85: 
L86: ```bash
L87: pta analyze https://github.com/user/monorepo --root packages/api -o ./output
L88: ```
L89: 
L90: ## Evidence Model
L91: 
L92: Every claim in the output cites structured evidence:
L93: 
L94: ```json
L95: {
L96:   "path": "server/index.ts",
L97:   "line_start": 92,
L98:   "line_end": 92,
L99:   "snippet_hash": "75d345a78f84",
L100:   "display": "server/index.ts:92"
L101: }
L102: ```
L103: 
L104: - `path` -- file path relative to project root
L105: - `line_start` / `line_end` -- 1-indexed line range (never 0)
L106: - `snippet_hash` -- first 12 hex chars of SHA-256 of the stripped line(s)
L107: - `display` -- human-readable location string
L108: 
L109: For file-existence evidence (e.g., lockfile detection):
L110: 
L111: ```json
L112: {
L113:   "kind": "file_exists",
L114:   "path": "package-lock.json",
L115:   "snippet_hash": "053150b640a7",
L116:   "display": "package-lock.json (file exists)"
L117: }
L118: ```
L119: 
L120: ### Verification
L121: 
L122: Snippet hashes are re-checked against source files: the analyzer re-reads the cited line range, strips whitespace, hashes the result, and confirms it matches the claimed hash. Claims that fail hash verification are capped at confidence 0.20 and marked `"status": "unverified"`.
L123: 
L124: **Important:** Hash verification confirms that a snippet exists at the cited location. It does not prove that the code behaves as described, is secure, or is free of bugs. PTA is not a security scanner, compliance certification tool, or correctness prover.
L125: 
L126: ### Whitespace Policy
L127: 
L128: Lines are stripped (trimmed) before hashing. This normalizes indentation differences across editors and formatters. Both evidence creation and verification use the same canonicalization.
L129: 
L130: ## Security
L131: 
L132: - **Symlink protection**: Every path component is checked. If any component in the path tree is a symlink, the file is rejected.
L133: - **Path containment**: All resolved paths must remain within the project root (`relative_to()` check after `resolve()`).
L134: - **Binary detection**: Null bytes in the first 4KB trigger rejection before text decoding.
L135: - **Traversal prevention**: `..` segments and absolute paths are rejected.
L136: - **Secret safety**: Only environment variable names are extracted, never their values.
L137: - **Self-skip**: The analyzer excludes its own source files from analysis to prevent false-positive pattern matches.
L138: 
L139: ## Output Files
L140: 
L141: ### `target_howto.json`
L142: 
L143: Operator manual with:
L144: - `prereqs` -- required runtimes
L145: - `install_steps` -- with commands and evidence
L146: - `config` -- environment variables with file:line references
L147: - `run_dev` / `run_prod` -- start commands with evidence
L148: - `replit_execution_profile` -- port binding, secrets, external APIs (Replit mode)
L149: - `unknowns` -- things the analyzer could not determine
L150: - `completeness` -- scoring with missing items
L151: 
L152: ### `claims.json`
L153: 
L154: Array of verifiable claims:
L155: - `statement` -- what is claimed
L156: - `confidence` -- 0.0 to 1.0
L157: - `evidence` -- array of evidence objects with `snippet_hash_verified: true/false`
L158: - `status` -- `"evidenced"` or `"unverified"`
L159: 
L160: ### `coverage.json`
L161: 
L162: - `mode_requested` / `mode` -- analysis mode
L163: - `scanned` / `skipped` -- file counts
L164: - `replit_detected` -- boolean
L165: - `replit_detection_evidence` -- evidence for Replit detection
L166: - `self_skip` -- analyzer self-exclusion details
L167: 
L168: ## Troubleshooting
L169: 
L170: ### "No module named 'core'"
L171: 
L172: Run from the repo root, or install with `pip install -e .`
L173: 
L174: ### Missing `DATABASE_URL`
L175: 
L176: The analyzer itself does not need a database. `DATABASE_URL` appears in outputs because it detects the target project's database configuration. No action needed for the analyzer.
L177: 
L178: ### Missing OpenAI environment variables
L179: 
L180: Only required when running without `--no-llm`. Set:
L181: ```bash
L182: export AI_INTEGRATIONS_OPENAI_API_KEY=your-key
L183: export AI_INTEGRATIONS_OPENAI_BASE_URL=https://api.openai.com/v1
L184: ```
L185: 
L186: ### "Port already in use"
L187: 
L188: The analyzer does not bind any ports. If you see port errors, they come from the target project's web server, not the analyzer.
L189: 
L190: ## Architecture
L191: 
L192: Two strictly separated layers:
L193: 
L194: 1. **Structural layer** (deterministic) — file indexing, pattern matching, evidence extraction. Outputs are reproducible and hash-verified against source artifacts.
L195: 2. **Semantic layer** (LLM-powered, optional) — architecture interpretation, risk assessment, integration analysis. Outputs are labeled as LLM-generated and carry confidence scores, not deterministic guarantees.
L196: 
L197: The `--no-llm` flag gives you only the structural layer. The semantic layer adds interpretation but is namespaced separately and never contaminates structural evidence.
L198: 
L199: ## Running Tests
L200: 
L201: ```bash
L202: bash scripts/smoke_test.sh
L203: ```
L204: 
L205: ## License
L206: 
L207: MIT

--- FILE: replit.md ---
L1: # Overview
L2: 
L3: **Program Totality Analyzer** — a full-stack web application that ingests software projects (via GitHub URL, local path, or live Replit workspace) and produces evidence-cited technical dossiers. The dossier covers what a target system is, how it works, how to use it, and what risks/unknowns exist. It combines a React frontend for submitting analysis requests and viewing results with an Express backend that manages projects/analyses in PostgreSQL and spawns a Python-based analyzer CLI for the actual code analysis.
L4: 
L5: ## User Preferences
L6: 
L7: Preferred communication style: Simple, everyday language.
L8: 
L9: ## System Architecture
L10: 
L11: ### Monorepo Structure
L12: 
L13: The project follows a three-zone monorepo pattern:
L14: 
L15: - **`client/`** — React SPA (frontend)
L16: - **`server/`** — Express API (backend)
L17: - **`shared/`** — Shared types, schemas, and route definitions used by both client and server
L18: 
L19: This avoids type drift between frontend and backend by sharing Zod schemas and TypeScript types from a single source of truth.
L20: 
L21: ### Frontend (`client/src/`)
L22: 
L23: - **Framework**: React 18 with TypeScript
L24: - **Routing**: Wouter (lightweight client-side router)
L25: - **State/Data Fetching**: TanStack React Query with polling for analysis status updates
L26: - **UI Components**: shadcn/ui (new-york style) built on Radix UI primitives
L27: - **Styling**: Tailwind CSS with CSS variables for theming (dark mode, cyan/neon aesthetic)
L28: - **Animations**: Framer Motion for page transitions and loading states
L29: - **Markdown Rendering**: react-markdown for displaying analysis dossiers
L30: - **Build Tool**: Vite with React plugin
L31: 
L32: Key pages:
L33: - `/` — Home page with URL input form and "Analyze Replit" button
L34: - `/projects` — List of previous analyses
L35: - `/projects/:id` — Detailed view of a specific analysis with tabs for dossier, claims, operator dashboard (operate.json), coverage, and unknowns
L36: 
L37: Path aliases: `@/` maps to `client/src/`, `@shared/` maps to `shared/`, `@assets/` maps to `attached_assets/`.
L38: 
L39: ### Backend (`server/`)
L40: 
L41: - **Framework**: Express 5 on Node.js
L42: - **Language**: TypeScript, run via `tsx` in dev
L43: - **API Pattern**: REST API under `/api/` prefix, route definitions shared via `shared/routes.ts`
L44: - **Dev Server**: Vite middleware in development (HMR via `server/vite.ts`), static file serving in production (`server/static.ts`)
L45: - **Build**: esbuild bundles server to `dist/index.cjs`; Vite builds client to `dist/public/`
L46: 
L47: Key API routes (defined in `server/routes.ts`):
L48: - `GET /api/projects` — List all projects
L49: - `POST /api/projects` — Create a new project (with mode: github/local/replit)
L50: - `GET /api/projects/:id` — Get project details
L51: - `GET /api/projects/:id/analysis` — Get analysis results
L52: - `POST /api/projects/:id/analyze` — Trigger analysis (spawns Python CLI)
L53: 
L54: ### Python Analyzer (`server/analyzer/`)
L55: 
L56: - **CLI**: `analyzer_cli.py` using Typer, supports three input modes:
L57:   - GitHub URL (`analyze <url>`)
L58:   - Local path (`analyze <path>`)
L59:   - Replit workspace (`analyze --replit`)
L60: - **Core**: `server/analyzer/src/analyzer.py` — orchestrates file acquisition, indexing, and LLM-powered analysis
L61: - **Operate Module**: `server/analyzer/src/core/operate.py` — deterministic (no LLM) extraction of operational data into `operate.json`
L62:   - Extracts boot commands, ports, integration points (endpoints, env vars, auth), deployment config, and runbook steps
L63:   - Uses three evidence tiers: EVIDENCED (file:line + SHA-256 snippet hash), INFERRED, UNKNOWN (with unknown_reason)
L64:   - Computes readiness scores (0-100) for boot, integrate, deploy categories
L65:   - Identifies operational gaps with severity ratings
L66: - **LLM Integration**: OpenAI API (via Replit AI Integrations env vars: `AI_INTEGRATIONS_OPENAI_API_KEY`, `AI_INTEGRATIONS_OPENAI_BASE_URL`)
L67: - The Express server spawns the Python analyzer as a child process
L68: 
L69: ### Database
L70: 
L71: - **Engine**: PostgreSQL (required, referenced via `DATABASE_URL` env var)
L72: - **ORM**: Drizzle ORM with `drizzle-zod` for schema-to-Zod validation
L73: - **Schema** (`shared/schema.ts`):
L74:   - `projects` — id, url, name, mode (github/local/replit), status (pending/analyzing/completed/failed), createdAt
L75:   - `analyses` — id, projectId, dossier (markdown text), claims (jsonb), howto (jsonb), coverage (jsonb), unknowns (jsonb), operate (jsonb), createdAt
L76: - **Chat models** (`shared/models/chat.ts`):
L77:   - `conversations` — id, title, createdAt
L78:   - `messages` — id, conversationId, role, content, createdAt
L79: - **Migrations**: Drizzle Kit with `drizzle-kit push` for schema sync
L80: - **Storage Layer**: `server/storage.ts` implements `IStorage` interface with `DatabaseStorage` class
L81: 
L82: ### Replit Integrations (`server/replit_integrations/` and `client/replit_integrations/`)
L83: 
L84: Pre-built integration modules for AI features:
L85: - **Chat** — Text-based conversation routes and storage using OpenAI
L86: - **Audio** — Voice recording, playback, speech-to-text, text-to-speech with AudioWorklet
L87: - **Image** — Image generation and editing via `gpt-image-1`
L88: - **Batch** — Rate-limited batch processing with retries for LLM calls
L89: 
L90: These are utility modules that can be registered on the Express app as needed.
L91: 
L92: ### Key Design Decisions
L93: 
L94: 1. **Shared route definitions** — `shared/routes.ts` defines API contracts (paths, input schemas, response schemas) used by both frontend hooks and backend handlers. This ensures type safety across the stack.
L95: 
L96: 2. **Python + Node hybrid** — The analyzer logic lives in Python (better ecosystem for code analysis, rich CLI output) while the web layer is Node/Express. The server spawns Python as a child process rather than using a microservice architecture, keeping deployment simple.
L97: 
L98: 3. **Evidence-first analysis** — The analyzer is designed to cite file paths and line ranges for every claim. When evidence is missing, it must label findings as inference/unknown rather than hallucinate.
L99: 
L100: 4. **Polling for status** — The frontend polls project status every 2 seconds while analysis is in progress, switching to static once completed/failed.
L101: 
L102: ## External Dependencies
L103: 
L104: ### Required Services
L105: - **PostgreSQL** — Primary database, must be provisioned with `DATABASE_URL` environment variable
L106: - **OpenAI API** (via Replit AI Integrations) — Powers the code analysis LLM calls
L107:   - `AI_INTEGRATIONS_OPENAI_API_KEY` — API key
L108:   - `AI_INTEGRATIONS_OPENAI_BASE_URL` — Base URL for API
L109: 
L110: ### Key NPM Packages
L111: - `express` v5 — HTTP server
L112: - `drizzle-orm` + `drizzle-kit` — Database ORM and migrations
L113: - `@tanstack/react-query` — Client-side data fetching and caching
L114: - `wouter` — Client-side routing
L115: - `react-markdown` — Markdown rendering for dossiers
L116: - `framer-motion` — Animations
L117: - `zod` + `drizzle-zod` — Runtime validation
L118: - `vite` — Frontend build and dev server
L119: - `esbuild` — Server build
L120: 
L121: ### Key Python Packages
L122: - `typer` — CLI framework
L123: - `openai` — LLM API client
L124: - `rich` — Console output formatting
L125: - `python-dotenv` — Environment variable loading
L126: 
L127: ### Dev/Build Tools
L128: - `tsx` — TypeScript execution for development
L129: - `tailwindcss` + `postcss` + `autoprefixer` — CSS toolchain
L130: - `@replit/vite-plugin-runtime-error-modal` — Dev error overlay

--- FILE: client/requirements.md ---
L1: ## Packages
L2: react-markdown | For rendering the analysis dossier
L3: framer-motion | For smooth page transitions and loading effects
L4: clsx | Utility for constructing className strings conditionally
L5: tailwind-merge | Utility for merging Tailwind classes efficiently
L6: 
L7: ## Notes
L8: - Theme: Technical, dark mode, "Program Totality Analyzer" aesthetic.
L9: - Fonts: Space Grotesk (headers), JetBrains Mono (code/data), Inter (UI).
L10: - Polling: Project status needs polling to show "Analyzing..." vs "Completed".

--- FILE: examples/README.md ---
L1: # Example Outputs
L2: 
L3: These are sample outputs from the Program Totality Analyzer running in `--no-llm` (deterministic) mode against its own workspace.
L4: 
L5: ## Files
L6: 
L7: - `out/target_howto.sample.json` — Operator manual: install steps, config, run commands, Replit execution profile. Every item cites file:line evidence with SHA-256 snippet hashes.
L8: - `out/coverage.sample.json` — Scan metadata: mode requested, files scanned/skipped, Replit detection evidence, self-skip configuration.
L9: 
L10: ## Generating Your Own
L11: 
L12: ```bash
L13: pta analyze --replit --no-llm -o ./my_output
L14: ```
L15: 
L16: Or for a GitHub repo:
L17: 
L18: ```bash
L19: pta analyze https://github.com/user/repo -o ./my_output
L20: ```
L21: 
L22: Or for a local folder:
L23: 
L24: ```bash
L25: pta analyze ./path/to/project -o ./my_output
L26: ```

--- FILE: docs/dossiers/lantern_program_totality_dossier.md ---
L1: ---
L2: title: Lantern Program Totality Dossier
L3: generated_by: PTA / Lantern
L4: mode: deterministic+curated
L5: date: 2026-02-14
L6: ---
L7: 
L8: # HALO-RECEIPTS: Program Totality Analyzer Dossier
L9: 
L10: ---
L11: 
L12: ## 1. **Identity of Target System**
L13: 
L14: **What it IS:**  
L15: HALO-RECEIPTS (AI Receipts) is a forensic verification system specifically designed for AI conversation transcripts. It provides cryptographic verification (SHA-256, Ed25519), immutable receipt storage, tamper-evident audit trails, forensic export capabilities, and extensive auditing for post-hoc analysis. This system is both the backend API server (Node.js/Express/PostgreSQL/Drizzle ORM) and a modern React UI, bundling forensic guarantees directly into receipt management and export (README.md:3,9,60–61; replit.md:4,11–12,14–24).
L16: 
L17: **What it is NOT:**  
L18: - **Not a real-time monitoring, content moderation, or multi-operator platform:** It is not designed for live chat moderation, direct truth judgment, or multi-user concurrency at the enforcement level (replit.md:55).
L19: - **Not a database engine:** Instead, it relies on PostgreSQL for durable state.
L20: - **Not a data lake or generic file archival platform.**
L21: - **Not a replacement for WORM-compliant log systems, but can integrate via checkpoint anchoring (see below).**
L22: - **Not a deployment framework:** The system expects to be deployed behind a reverse proxy or PaaS (README.md:24; SECURITY.md:54).
L23: 
L24: ---
L25: 
L26: ## 2. **Purpose & Jobs-to-be-done**
L27: 
L28: - **Forensic Conversation Integrity:** Operators can guarantee, via public proofs, that a transcript or "receipt" has not been tampered with since its recording date (README.md:9; replit.md:4).
L29: - **Immutable Logging & Audit Trails:** Ensures all receipt actions (append, lock, kill switch, export, audit actions) are tracked in an append-only, hash-linked audit log, detecting insertions, deletions, reordering, and version tampering (SECURITY.md:8–10; STATE.md:165–169).
L30: - **Cryptographic Verification:** Verifies that every receipt chain and audit log entry is both hash-linked (SHA-256) and checkpoint signed (Ed25519), with optional external anchoring (replit.md:36–46; STATE.md:116–121).
L31: - **Forensic Export and Proof Packs:** Allows export of forensic packs (JSON) that can be offline verified and admitted as tamper-evident evidence (STATE.md:122–125; scripts/ci-forensic-gate.sh).
L32: - **Regulatory Alignment:** System features mapped to compliance goals (21 CFR, HIPAA, SOC2, etc.) (replit.md:50, STATE.md:137).
L33: - **Operator/Evidence Reliability:** Designed to provide demonstrable evidence for courts, regulators, or internal review.
L34: 
L35: ---
L36: 
L37: ## 3. **Capability Map**
L38: 
L39: | Capability             | Mechanism / Implementation | Evidence                                    |
L40: |------------------------|---------------------------|---------------------------------------------|
L41: | SHA-256 Hash Verification   | Canonicalized (c14n-v1) JSON hash | README.md:73–74; STATE.md:17,20             |
L42: | Ed25519 Signatures     | Checkpoint signing, chain   | STATE.md:18,116–121; replit.md:36           |
L43: | Immutable Storage      | Receipt lock, no mutation  | README.md:75; STATE.md:21,158–159           |
L44: | Kill Switch            | Irreversible flag, disables outputs | README.md:76; STATE.md:22,157                |
L45: | Audit Logs             | Append-only, hash-chained table | STATE.md:25–29,162                           |
L46: | Forensic Export/Import | export_forensic_pack, verify_forensic_pack scripts | STATE.md:123–126                              |
L47: | Forensic Sensors       | Interpreter, summarizer, claim extractor | README.md:78; STATE.md:80,85                  |
L48: | Policy Enforcement     | Zod schemas, request shape limits | SECURITY.md:20–23                            |
L49: | API Rate Limiting      | Per-IP, in-memory          | SECURITY.md:26–29; STATE.md:94; package.json:61 |
L50: | Key Rotation & Anchoring | Multi-key support, anchor backends | replit.md:43–47                            |
L51: | Secure API Structure   | API_KEY in x-api-key header; private/public endpoints | SECURITY.md:15–16,72                           |
L52: | Client Auth Isolation  | LLMs see only transcript content | SECURITY.md:39–40; STATE.md:160,20           |
L53: | UI Export & Compare    | Side-by-side comparison, JSONL/CSV export | README.md:143; replit.md:25,23                |
L54: | Structured Logging     | JSON logs, in-memory counters | STATE.md:106–107,184                          |
L55: | Health Checks          | /api/health, /api/ready    | STATE.md:37,43,100–101; docs/API_CONTRACTS.md:11,24 |
L56: 
L57: ---
L58: 
L59: ## 4. **Architecture Snapshot**
L60: 
L61: - **Frontend:** React (wouter router), Tailwind, shadcn/ui (README.md:59, client/src/App.tsx)
L62: - **Backend:** Node.js 20, Express, Drizzle ORM (README.md:60–61; package.json)
L63: - **Database:** PostgreSQL 14+ (README.md:24, .env.example:5)
L64: - **Cryptography:** Node.js crypto (SHA-256), Ed25519 (STATE.md:18,116)
L65: - **Session:** express-session, connect-pg-simple (package.json:51,57)
L66: - **Audit Trail:** Hash-linking via prev_hash and payload_v, audit_head singleton row (STATE.md:9,25–29,48,52; drizzle.config.ts:9)
L67: - **Forensic Export:** TypeScript scripts in `/scripts`, results in JSON proof packs (STATE.md:123–126)
L68: - **CI/CD:** GitHub Actions, drift guard scripts, reproducible verifier zips (replit.md:39–42,57)
L69: 
L70: ---
L71: 
L72: ## 5. **How to Use the Target System**
L73: 
L74: ### **Operator Manual**
L75: 
L76: #### **A. Prerequisites**
L77: 
L78: 1. **Install:**
L79:    - Node.js 20+, npm (`npm -v`/`node -v`)
L80:    - PostgreSQL 14+ running and accessible (README.md:23–24)
L81:    - jq, unzip, python3 for export/ops scripts (see replit.nix, scripts/ci-forensic-gate.sh)
L82:    - TypeScript, tsx, drizzle-kit, installed via npm as devDependencies (package.json)
L83: 
L84: #### **B. Installation**
L85: 
L86: 1. **Clone Repository**
L87: 2. `npm install`  
L88:    Installs all dependencies (README.md:29)
L89: 3. `cp .env.example .env`  
L90:    Copy template env config (README.md:33)
L91: 4. **Edit `.env`**:  
L92:    Set `DATABASE_URL`, `API_KEY`, `SESSION_SECRET` and all other required variables suitably (README.md:34; .env.example:5,10,23)
L93: 5. **(Optional: Replit):**
L94:    - Use the "Run on Replit" badge or Replit sidebar GUI (README.md:17)
L95: 
L96: #### **C. Configuration**
L97: 
L98: Set the following in `.env` (names only, do not provide values):
L99: - **DATABASE_URL:** PostgreSQL connection string (.env.example:5)
L100: - **API_KEY:** Required for private endpoints (.env.example:10; SECURITY.md:15)
L101: - **SESSION_SECRET:** Strong, random string (.env.example:23; SECURITY.md:71)
L102: - **NODE_ENV:** development/production (.env.example:13)
L103: - **PORT:** Default 5000 (.env.example:14)
L104: - Other optional: TRANSCRIPT_MODE, CHECKPOINT_INTERVAL, CHECKPOINT_ANCHOR_TYPE, etc. (.env.example, STATE.md:118, replit.md:45)
L105: 
L106: #### **D. Database Init**
L107: 
L108: - Run: `npm run db:push`  
L109:   This applies the schema to PostgreSQL (README.md:39)
L110: 
L111: #### **E. Development Server**
L112: 
L113: - Run: `npm run dev`  
L114:   Runs server in development mode (README.md:44)
L115: - Visit: [http://localhost:5000](http://localhost:5000) (README.md:47)
L116: 
L117: #### **F. Production Build**
L118: 
L119: - Run: `npm run build`  
L120:   Compile frontend and backend (README.md:52)
L121: - Set `NODE_ENV=production`, then  
L122:   `npm run start` (README.md:53)
L123: - Server now on port specified in env (default 5000) (README.md:47, .replit:10,14, .env.example:14)
L124: 
L125: #### **G. Example API Usage**
L126: 
L127: - Health Check:  
L128:   `curl http://localhost:5000/api/health` (docs/API_CONTRACTS.md:11)
L129: - Readiness:  
L130:   `curl http://localhost:5000/api/ready` (docs/API_CONTRACTS.md:24)
L131: - Verify Audit (requires API_KEY):  
L132:   `curl -H "x-api-key: <API_KEY>" http://localhost:5000/api/audit/verify` (docs/API_CONTRACTS.md:64)
L133: - Create & Lock Receipts, Get all Receipts, Kill Switch, etc.:  
L134:   See usage_examples in HOWTO (docs/API_CONTRACTS.md)
L135: 
L136: #### **H. Verification & Forensics**
L137: 
L138: - Check schema: `npm run db:push` (README.md:39)
L139: - Verify audit chain:  
L140:   `curl -H "x-api-key: <API_KEY>" http://localhost:5000/api/audit/verify` (STATE.md:206)
L141: - Export forensic pack:**  
L142:   `npx tsx scripts/export_forensic_pack.ts --output <pack.json>`
L143: - Offline verify pack:  
L144:   `npx tsx scripts/verify_forensic_pack.ts <pack.json>` (scripts/ci-forensic-gate.sh:42)
L145: - Tamper detection: run the same after editing pack, expect fail (scripts/ci-forensic-gate.sh:61–84)
L146:   
L147: #### **I. Common Failures**
L148: 
L149: | Symptom                        | Cause                              | Fix                                                  | Evidence                |
L150: |--------------------------------|------------------------------------|------------------------------------------------------|-------------------------|
L151: | 401 Unauthorized               | Wrong/missing API_KEY              | Set correct `x-api-key` header, check .env           | SECURITY.md:15          |
L152: | DB connection errors/crash     | Bad DATABASE_URL, DB offline/wrong | Check credentials, service, version                  | drizzle.config.ts:3     |
L153: | Server not running on port     | App not started, port conflict     | Check logs, ensure PORT=5000, check if in use        | .replit:10              |
L154: | Forensic pack tamper undetected| Bug or script not installed        | Re-export, ensure proper script in place             | scripts/ci-forensic-gate.sh:61–84 |
L155: 
L156: ---
L157: 
L158: ## 6. **Integration Surface**
L159: 
L160: - **REST API:**  
L161:   Well-documented REST endpoints (`/api/health`, `/api/ready`, `/api/receipts`, `/api/audit/verify`, `/api/receipts/:id/lock`, `/api/receipts/:id/kill-switch`, etc.) (docs/API_CONTRACTS.md)
L162: - **API Authentication:**  
L163:   API key required for all non-public (write or sensitive) endpoints via `x-api-key` HTTP header (SECURITY.md:15, .env.example:10)
L164: - **Webhooks:**  
L165:   Unknown — evidence needed: No explicit webhook example or config found for outbound push/integrations.
L166: - **Data Formats:**  
L167:   JSON REST, all API schemas validated by Zod (STATE.md:95; SECURITY.md:20).
L168: - **Export/Import:**  
L169:   Forensic packs as canonical JSON, offline verifier script can process proof packs and verify signatures (STATE.md:123–125)
L170: - **SDKs:**  
L171:   None provided; interaction via HTTP API and TypeScript scripts.
L172: 
L173: ---
L174: 
L175: ## 7. **Data & Security Posture**
L176: 
L177: - **Data Storage:**  
L178:   All core state in PostgreSQL (receipts, audit trail, checkpoints; .env.example:5; README.md:61)
L179: - **Immutable guarantees:**  
L180:   Lock and kill-switch state prevent subsequent edits (README.md:75,76; STATE.md:21–22)
L181: - **Audit Log:**  
L182:   Hash-linked, append-only, verified at both write and operator demand (STATE.md:25–29)
L183: - **Cryptography:**  
L184:   Canonical JSON SHA-256 for all payloads, Ed25519 for checkpoint signing (STATE.md:17–19,116)
L185: - **External Anchoring:**  
L186:   Pluggable anchors (LogOnly, S3WormAnchor, Rfc3161TsaAnchor), config via `CHECKPOINT_ANCHOR_TYPE` (replit.md:45; STATE.md:170–173)
L187: - **Authentication:**  
L188:   API_KEY via header for all writes and sensitive queries, stored only as secret (SECURITY.md:15–17,72,84)
L189: - **Input Validation:**  
L190:   Zod schemas, 1MB max body, JSON only, UTF-8 validation (SECURITY.md:20–23)
L191: - **Rate Limiting:**  
L192:   Per-IP, endpoint and overall, in-memory only (SECURITY.md:26–29; STATE.md:94)
L193: - **Headers:**  
L194:   X-Content-Type-Options, X-Frame-Options, Referrer-Policy, Permissions-Policy (SECURITY.md:32–36; STATE.md:97)
L195: - **Session Security:**  
L196:   express-session with SESSION_SECRET, connect-pg-simple store (package.json:51,57; .env.example:23)
L197: - **No Logging of Secrets:**  
L198:   Explicitly forbidden, audit logs never include `API_KEY`/secrets (SECURITY.md:17,90)
L199: 
L200: ---
L201: 
L202: ## 8. **Operational Reality**
L203: 
L204: - **Server:**  
L205:   Runs via `npm run dev` (development) or production `npm run build && npm run start` (README.md:44,52–53; .replit:2,18)
L206: - **Port:**  
L207:   Default 5000 (README.md:47; .env.example:14; .replit:10,14)
L208: - **Database:**  
L209:   PostgreSQL 14+ required and always available; credentials in env (README.md:24; drizzle.config.ts)
L210: - **Secrets:**  
L211:   All secrets via `.env`; no default session or API key in production (SECURITY.md:84)
L212: - **No Built-in TLS:**  
L213:   Not exposed directly; deploy behind HTTPS proxy (SECURITY.md:54; README.md:24)
L214: - **CI/CD:**  
L215:   Github Actions runs type check, db:push, tests, drift guards, build, releases artifacts (STATE.md:111; replit.md:39–42)
L216: - **Counters/Rate-Limits:**  
L217:   In-memory, reset on process restart (STATE.md:107; SECURITY.md:62–64)
L218: - **Persistent Storage:**  
L219:   No special data directory—state in PostgreSQL only.
L220: - **Logs:**  
L221:   Structured JSON to console; location for interactive review unknown — evidence needed (STATE.md:106)
L222: 
L223: ---
L224: 
L225: ## 9. **Maintainability & Change Risk**
L226: 
L227: - **Well Bounded:**  
L228:   Security, business logic, and cryptography are isolated and formalized (STATE.md:149–162)
L229: - **Explicit Invariants and Forbidden Practices:**  
L230:   Canonicalization pipeline, no mock data, strict version/hashing rules (STATE.md:149–162,186–193)
L231: - **Codebase Size:**  
L232:   Large (`routes.ts` >2k lines); risk for routing/merge conflicts (STATE.md:183)
L233: - **Rate Limiter Limitation:**  
L234:   In-memory counters/rate-limiting, resets on restart; persistence is a punchlist item (STATE.md:184,219)
L235: - **Key rotation and signature abstraction:**  
L236:   Documented plan, proof-tested, rotation protocol in THREAT_MODEL.md (replit.md:43–44,60)
L237: - **Danger Areas:**  
L238:   Fully-privileged DB admin can bypass all checks without external anchor; risk documented (STATE.md:172–173).
L239: - **Tests:**  
L240:   42 tests (STATE.md:194). CI runs coverage, canonicalization, audit drift/adapter boundary guards (STATE.md:111–114)
L241: 
L242: ---
L243: 
L244: ## 10. **Replit Execution Profile**
L245: 
L246: - **Default Replit run:** `npm run dev` ([.replit:2])
L247: - **Modules:** Node 20, PostgreSQL 16, web via Replit ([.replit:1])
L248: - **PORT:** 5000 (mapped to external 80) ([.replit:10–11,14])
L249: - **Build on Deploy:** Runs `npm run build` ([.replit:19])
L250: - **Production Entrypoint:** `node ./dist/index.cjs` ([.replit:18])
L251: - **Replit Special Integration:** VITE_DEV_API_KEY set for development ([.replit:45]), GitHub integration possible ([.env.example:27–29])
L252: - **Nix Packages:** jq, unzip for ops scripts ([.replit:7])
L253: 
L254: ---
L255: 
L256: ## 11. **Unknowns / Missing Evidence**
L257: 
L258: | What is Missing | Why It Matters | Evidence Needed |
L259: |-----------------|----------------|----------------|
L260: | Production deployment details outside Replit (systemd/Docker/PM2) | Real-world ops, non-Replit platforms | Dockerfile, systemd service, or reverse proxy config |
L261: | Database initialization beyond drizzle-kit | Custom DB/user privileges, stateful setups | Database schema, role guides, SQL init scripts |
L262: | Key rotation/generation procedure for API_KEY or SESSION_SECRET | Long-term ops, secops | Step-by-step key management documentation |
L263: | Log path or viewing commands | Troubleshooting, support | Log file locations or sample log tail commands |
L264: | Standalone front-end hosting commands | Non-Replit, split hosting | Front-end build/start manual, production hosting instructions |
L265: | Webhooks or outbound events | Integration with SIEM/alerting | Outbound webhook config or documentation |
L266: 
L267: ---
L268: 
L269: ## 12. **Receipts (Evidence Index)**
L270: 
L271: **All claims above are strictly supported by:**
L272: 
L273: - **README.md:** lines 3,9,17–47,52–56,59–79,90.
L274: - **replit.md:** lines 4,11–61 (core capabilities, architecture).
L275: - **.env.example:** lines 5,10,13,14,18,23,27–29.
L276: - **STATE.md:** lines 17–23,25–48,49–212,149–162,165–193,194–214 (invariants, tests, capability inventory, ops, threat model, audit chain).
L277: - **SECURITY.md:** lines 8–17,20–29,32–36,39–41,54,62–64,71–90.
L278: - **drizzle.config.ts:** line 3 (database connectivity).
L279: - **.replit:** lines 2,10,14,18–19,45 (Replit settings).
L280: - **package.json:** dev/prod dependencies, scripts: "dev", "build", "start", "db:push" (lines 7–12,51,57,61).
L281: - **docs/API_CONTRACTS.md:** endpoints, usage examples.
L282: - **scripts/ci-forensic-gate.sh:** lines 42,61–84 (forensic scripts).
L283: - **client/src/App.tsx & components:** UI routes, health/audit banners.
L284:   
L285: **Specific references cross-index with HOWTO JSON, which extracts and hashes the underlying source text (e.g., README.md:39).**
L286: 
L287: ---
L288: 
L289: **End of Dossier.**

--- FILE: output/DOSSIER.md ---
L1: # Program Totality Analyzer — Deterministic Dossier
L2: 
L3: **Mode:** `--no-llm` (deterministic extraction only, no LLM calls)
L4: 
L5: ## 1. File Index Summary
L6: - Files scanned: see index.json
L7: - Self-skip: 26 analyzer files excluded
L8: 
L9: ## 2. Replit Execution Profile
L10: - **Is Replit:** True
L11: - **Run command:** `npm run dev`
L12: - **Language:** nodejs
L13: - **Port:** Uses PORT env var; actual port determined at runtime. In Replit, PORT is injected.
L14: - **Secrets (3):** DATABASE_URL, AI_INTEGRATIONS_OPENAI_API_KEY, AI_INTEGRATIONS_OPENAI_BASE_URL
L15: - **External APIs:** OpenAI
L16: 
L17: ## 3. Operator Manual (Deterministic)
L18: ```json
L19: {
L20:   "prereqs": [
L21:     "Node.js",
L22:     "Python"
L23:   ],
L24:   "install_steps": [
L25:     {
L26:       "step": "Install Node dependencies",
L27:       "command": "npm ci",
L28:       "evidence": {
L29:         "kind": "file_exists",
L30:         "path": "package-lock.json",
L31:         "snippet_hash": "053150b640a7",
L32:         "display": "package-lock.json (file exists)"
L33:       }
L34:     },
L35:     {
L36:       "step": "Install Python dependencies",
L37:       "command": "pip install .",
L38:       "evidence": {
L39:         "kind": "file_exists",
L40:         "path": "pyproject.toml",
L41:         "snippet_hash": "50c86b7ed8ac",
L42:         "display": "pyproject.toml (file exists)"
L43:       }
L44:     }
L45:   ],
L46:   "config": [
L47:     {
L48:       "name": "DATABASE_URL",
L49:       "purpose": "Secret referenced in code (see evidence)",
L50:       "evidence": {
L51:         "path": "drizzle.config.ts",
L52:         "line_start": 3,
L53:         "line_end": 3,
L54:         "snippet_hash": "a19790628fbe",
L55:         "display": "drizzle.config.ts:3"
L56:       }
L57:     },
L58:     {
L59:       "name": "AI_INTEGRATIONS_OPENAI_API_KEY",
L60:       "purpose": "Secret referenced in code (see evidence)",
L61:       "evidence": {
L62:         "path": "server/replit_integrations/audio/client.ts",
L63:         "line_start": 10,
L64:         "line_end": 10,
L65:         "snippet_hash": "05da5f1b1281",
L66:         "display": "server/replit_integrations/audio/client.ts:10"
L67:       }
L68:     },
L69:     {
L70:       "name": "AI_INTEGRATIONS_OPENAI_BASE_URL",
L71:       "purpose": "Secret referenced in code (see evidence)",
L72:       "evidence": {
L73:         "path": "server/replit_integrations/audio/client.ts",
L74:         "line_start": 11,
L75:         "line_end": 11,
L76:         "snippet_hash": "1f70e6a77d42",
L77:         "display": "server/replit_integrations/audio/client.ts:11"
L78:       }
L79:     }
L80:   ],
L81:   "run_dev": [
L82:     {
L83:       "step": "Start dev server",
L84:       "command": "npm run dev",
L85:       "evidence": {
L86:         "path": "package.json",
L87:         "line_start": 7,
L88:         "line_end": 7,
L89:         "snippet_hash": "fd240a9dc053",
L90:         "display": "package.json:7"
L91:       }
L92:     }
L93:   ],
L94:   "run_prod": [
L95:     {
L96:       "step": "Build for production",
L97:       "command": "npm run build",
L98:       "evidence": {
L99:         "path": "package.json",
L100:         "line_start": 8,
L101:         "line_end": 8,
L102:         "snippet_hash": "79d8bdf275d6",
L103:         "display": "package.json:8"
L104:       }
L105:     },
L106:     {
L107:       "step": "Start production",
L108:       "command": "npm start",
L109:       "evidence": {
L110:         "path": "package.json",
L111:         "line_start": 9,
L112:         "line_end": 9,
L113:         "snippet_hash": "020435ddf436",
L114:         "display": "package.json:9"
L115:       }
L116:     }
L117:   ],
L118:   "usage_examples": [],
L119:   "verification_steps": [],
L120:   "common_failures": [],
L121:   "unknowns": [
L122:     {
L123:       "what_is_missing": "Semantic analysis of code purpose and architecture",
L124:       "why_it_matters": "Cannot determine system intent, integration patterns, or risk factors without LLM analysis",
L125:       "what_evidence_needed": "Re-run without --no-llm flag for full analysis"
L126:     }
L127:   ],
L128:   "missing_evidence_requests": [],
L129:   "replit_execution_profile": {
L130:     "run_command": "npm run dev",
L131:     "language": "nodejs",
L132:     "port_binding": {
L133:       "port": null,
L134:       "binds_all_interfaces": true,
L135:       "uses_env_port": true,
L136:       "evidence": [
L137:         {
L138:           "path": "server/index.ts",
L139:           "line_start": 92,
L140:           "line_end": 92,
L141:           "snippet_hash": "75d345a78f84",
L142:           "display": "server/index.ts:92"
L143:         },
L144:         {
L145:           "path": "server/index.ts",
L146:           "line_start": 96,
L147:           "line_end": 96,
L148:           "snippet_hash": "9b7206f3d09a",
L149:           "display": "server/index.ts:96"
L150:         }
L151:       ]
L152:     },
L153:     "required_secrets": [
L154:       {
L155:         "name": "DATABASE_URL",
L156:         "referenced_in": [
L157:           {
L158:             "path": "drizzle.config.ts",
L159:             "line_start": 3,
L160:             "line_end": 3,
L161:             "snippet_hash": "a19790628fbe",
L162:             "display": "drizzle.config.ts:3"
L163:           },
L164:           {
L165:             "path": "drizzle.config.ts",
L166:             "line_start": 12,
L167:             "line_end": 12,
L168:             "snippet_hash": "1005be19f14a",
L169:             "display": "drizzle.config.ts:12"
L170:           },
L171:           {
L172:             "path": "server/db.ts",
L173:             "line_start": 7,
L174:             "line_end": 7,
L175:             "snippet_hash": "a19790628fbe",
L176:             "display": "server/db.ts:7"
L177:           },
L178:           {
L179:             "path": "server/db.ts",
L180:             "line_start": 13,
L181:             "line_end": 13,
L182:             "snippet_hash": "111f33de9945",
L183:             "display": "server/db.ts:13"
L184:           }
L185:         ]
L186:       },
L187:       {
L188:         "name": "AI_INTEGRATIONS_OPENAI_API_KEY",
L189:         "referenced_in": [
L190:           {
L191:             "path": "server/replit_integrations/audio/client.ts",
L192:             "line_start": 10,
L193:             "line_end": 10,
L194:             "snippet_hash": "05da5f1b1281",
L195:             "display": "server/replit_integrations/audio/client.ts:10"
L196:           },
L197:           {
L198:             "path": "server/replit_integrations/chat/routes.ts",
L199:             "line_start": 6,
L200:             "line_end": 6,
L201:             "snippet_hash": "05da5f1b1281",
L202:             "display": "server/replit_integrations/chat/routes.ts:6"
L203:           },
L204:           {
L205:             "path": "server/replit_integrations/image/client.ts",
L206:             "line_start": 6,
L207:             "line_end": 6,
L208:             "snippet_hash": "05da5f1b1281",
L209:             "display": "server/replit_integrations/image/client.ts:6"
L210:           }
L211:         ]
L212:       },
L213:       {
L214:         "name": "AI_INTEGRATIONS_OPENAI_BASE_URL",
L215:         "referenced_in": [
L216:           {
L217:             "path": "server/replit_integrations/audio/client.ts",
L218:             "line_start": 11,
L219:             "line_end": 11,
L220:             "snippet_hash": "1f70e6a77d42",
L221:             "display": "server/replit_integrations/audio/client.ts:11"
L222:           },
L223:           {
L224:             "path": "server/replit_integrations/chat/routes.ts",
L225:             "line_start": 7,
L226:             "line_end": 7,
L227:             "snippet_hash": "1f70e6a77d42",
L228:             "display": "server/replit_integrations/chat/routes.ts:7"
L229:           },
L230:           {
L231:             "path": "server/replit_integrations/image/client.ts",
L232:             "line_start": 7,
L233:             "line_end": 7,
L234:             "snippet_hash": "1f70e6a77d42",
L235:             "display": "server/replit_integrations/image/client.ts:7"
L236:           }
L237:         ]
L238:       }
L239:     ],
L240:     "external_apis": [
L241:       {
L242:         "api": "OpenAI",
L243:         "evidence_files": [
L244:           {
L245:             "path": "server/replit_integrations/audio/client.ts",
L246:             "line_start": 1,
L247:             "line_end": 1,
L248:             "snippet_hash": "1d3dd608c3bb",
L249:             "display": "server/replit_integrations/audio/client.ts:1"
L250:           },
L251:           {
L252:             "path": "server/replit_integrations/audio/routes.ts",
L253:             "line_start": 3,
L254:             "line_end": 3,
L255:             "snippet_hash": "2f87d29d3b03",
L256:             "display": "server/replit_integrations/audio/routes.ts:3"
L257:           },
L258:           {
L259:             "path": "server/replit_integrations/chat/routes.ts",
L260:             "line_start": 2,
L261:             "line_end": 2,
L262:             "snippet_hash": "4db7290b0afd",
L263:             "display": "server/replit_integrations/chat/routes.ts:2"
L264:           },
L265:           {
L266:             "path": "server/replit_integrations/image/routes.ts",
L267:             "line_start": 2,
L268:             "line_end": 2,
L269:             "snippet_hash": "7fd5b3abbeee",
L270:             "display": "server/replit_integrations/image/routes.ts:2"
L271:           },
L272:           {
L273:             "path": "server/replit_integrations/image/client.ts",
L274:             "line_start": 2,
L275:             "line_end": 2,
L276:             "snippet_hash": "1d3dd608c3bb",
L277:             "display": "server/replit_integrations/image/client.ts:2"
L278:           }
L279:         ]
L280:       }
L281:     ],
L282:     "deployment_assumptions": [
L283:       "Binds to 0.0.0.0 (all interfaces)",
L284:       "No Dockerfile - depends on Replit runtime or manual setup",
L285:       "Requires 3 secret(s): DATABASE_URL, AI_INTEGRATIONS_OPENAI_API_KEY, AI_INTEGRATIONS_OPENAI_BASE_URL"
L286:     ],
L287:     "observability": {
L288:       "logging": true,
L289:       "health_endpoint": true,
L290:       "evidence": [
L291:         {
L292:           "path": "script/build.ts",
L293:           "line_start": 38,
L294:           "line_end": 38,
L295:           "snippet_hash": "2f74cc3fdab1",
L296:           "display": "script/build.ts:38"
L297:         },
L298:         {
L299:           "path": "shared/schema.ts",
L300:           "line_start": 10,
L301:           "line_end": 10,
L302:           "snippet_hash": "6ccc8e5d45a7",
L303:           "display": "shared/schema.ts:10"
L304:         }
L305:       ]
L306:     },
L307:     "limitations": [
L308:       "Deterministic mode (--no-llm): no semantic analysis performed"
L309:     ]
L310:   },
L311:   "completeness": {
L312:     "score": 62,
L313:     "max": 100,
L314:     "missing": [
L315:       "verification_steps: no step with both a runnable command and verified evidence",
L316:       "usage_examples: no examples with meaningful descriptions"
L317:     ],
L318:     "deductions": [
L319:       "-3 for 1 unknown(s)"
L320:     ],
L321:     "notes": "-3 for 1 unknown(s); No Dockerfile found; 1 unknown(s) reported"
L322:   }
L323: }
L324: ```
L325: 
L326: ## 4. Limitations
L327: - This dossier was generated in `--no-llm` mode
L328: - No semantic analysis, claims extraction, or architecture inference was performed
L329: - For full analysis, re-run without `--no-llm`

--- FILE: output/REPORT_ENGINEER.md ---
L1: # Program Totality Report — Engineer View
L2: 
L3: **EvidencePack Version:** 1.0
L4: **Tool Version:** 0.1.0
L5: **Generated:** 2026-02-15T08:28:39.917837+00:00
L6: **Mode:** replit
L7: **Run ID:** 43f6636690d6
L8: 
L9: ---
L10: 
L11: ## PTA Contract Audit — Run 43f6636690d6
L12: 
L13: ### 1. System Snapshot
L14: 
L15: | Measure | Value |
L16: |---------|-------|
L17: | Files Analyzed | 158 |
L18: | Files Seen (incl. skipped) | 184 |
L19: | Files Skipped | 26 |
L20: | Claims Extracted | 17 |
L21: | Claims with Deterministic Evidence | 15 |
L22: | Unknown Governance Categories | 9 |
L23: | Verified Structural Categories | 0 |
L24: | Partial Coverage | Yes |
L25: 
L26: ### 2. Deterministic Coverage Index (DCI v1)
L27: 
L28: **Score:** 88.24%
L29: **Formula:** `verified_claims / total_claims`
L30: 
L31: 15 of 17 extracted claims contain hash-verified evidence.
L32: 
L33: This measures claim-to-evidence visibility only.
L34: It does not measure code quality, security posture, or structural surface coverage.
L35: 
L36: ### 3. Reporting Completeness Index (RCI)
L37: 
L38: **Score:** 50.08%
L39: **Formula:** `average(claims_coverage, unknowns_coverage, howto_completeness)`
L40: 
L41: | Component | Score |
L42: |-----------|-------|
L43: | claims_coverage | 88.24% |
L44: | unknowns_coverage | 0.00% |
L45: | howto_completeness | 62.00% |
L46: 
L47: RCI is a documentation completeness metric.
L48: It is not a security score and does not imply structural sufficiency.
L49: 
L50: ### 4. Structural Visibility (DCI v2)
L51: 
L52: **Status:** not_implemented
L53: **Formula (reserved):** `verified_structural_items / total_structural_surface`
L54: 
L55: Routes, dependencies, schemas, and enforcement extractors are not active.
L56: Structural surface visibility is intentionally reported as null rather than estimated.
L57: This prevents silent overstatement of governance posture.
L58: 
L59: ### 5. Epistemic Posture
L60: 
L61: PTA explicitly reports:
L62: - What is deterministically verified.
L63: - What is unknown.
L64: - What is not implemented.
L65: - What requires dedicated extractors.
L66: 
L67: There is no inference-based promotion from UNKNOWN to VERIFIED.
L68: 
L69: ---
L70: 
L71: ## Verified: Data & Security Posture
L72: 
L73: ### System requires 3 secret(s): DATABASE_URL, AI_INTEGRATIONS_OPENAI_API_KEY, AI_INTEGRATIONS_OPENAI_BASE_URL
L74: Confidence: 55%
L75: - Evidence: `drizzle.config.ts:3` (hash: `a19790628fbe`)
L76: - Evidence: `server/replit_integrations/audio/client.ts:10` (hash: `05da5f1b1281`)
L77: - Evidence: `server/replit_integrations/audio/client.ts:11` (hash: `1f70e6a77d42`)
L78: 
L79: ### Secret "DATABASE_URL" is referenced in 4 file(s)
L80: Confidence: 50%
L81: - Evidence: `drizzle.config.ts:3` (hash: `a19790628fbe`)
L82: - Evidence: `drizzle.config.ts:12` (hash: `1005be19f14a`)
L83: 
L84: ### Secret "AI_INTEGRATIONS_OPENAI_API_KEY" is referenced in 3 file(s)
L85: Confidence: 50%
L86: - Evidence: `server/replit_integrations/audio/client.ts:10` (hash: `05da5f1b1281`)
L87: - Evidence: `server/replit_integrations/chat/routes.ts:6` (hash: `05da5f1b1281`)
L88: 
L89: ### Secret "AI_INTEGRATIONS_OPENAI_BASE_URL" is referenced in 3 file(s)
L90: Confidence: 50%
L91: - Evidence: `server/replit_integrations/audio/client.ts:11` (hash: `1f70e6a77d42`)
L92: - Evidence: `server/replit_integrations/chat/routes.ts:7` (hash: `1f70e6a77d42`)
L93: 
L94: ## Verified: How to Use the Target System
L95: 
L96: ### npm script "dev" runs: NODE_ENV=development tsx server/index.ts
L97: Confidence: 60%
L98: - Evidence: `package.json:7` (hash: `fd240a9dc053`)
L99: 
L100: ### npm script "build" runs: tsx script/build.ts
L101: Confidence: 60%
L102: - Evidence: `package.json:8` (hash: `79d8bdf275d6`)
L103: 
L104: ### npm script "start" runs: NODE_ENV=production node dist/index.cjs
L105: Confidence: 60%
L106: - Evidence: `package.json:9` (hash: `020435ddf436`)
L107: 
L108: ### Server binds to 0.0.0.0 (all interfaces)
L109: Confidence: 55%
L110: - Evidence: `server/index.ts:92` (hash: `75d345a78f84`)
L111: - Evidence: `server/index.ts:96` (hash: `9b7206f3d09a`)
L112: 
L113: ### Server port is configured via environment variable
L114: Confidence: 55%
L115: - Evidence: `server/index.ts:92` (hash: `75d345a78f84`)
L116: - Evidence: `server/index.ts:96` (hash: `9b7206f3d09a`)
L117: 
L118: ### Replit run command: npm run dev
L119: Confidence: 55%
L120: - Evidence: `.replit:2` (hash: `96fa2e5505e4`)
L121: - Evidence: `.replit:5` (hash: `550b970621c2`)
L122: 
L123: ## Verified: Integration Surface
L124: 
L125: ### Key dependencies: drizzle-orm, express, openai, react
L126: Confidence: 50%
L127: - Evidence: `package.json:13` (hash: `f7eebadd079d`)
L128: 
L129: ### External API dependency: OpenAI
L130: Confidence: 45%
L131: - Evidence: `server/replit_integrations/audio/client.ts:1` (hash: `1d3dd608c3bb`)
L132: - Evidence: `server/replit_integrations/audio/routes.ts:3` (hash: `2f87d29d3b03`)
L133: 
L134: ### Database schema/migration files detected: drizzle.config.ts, server/db.ts, shared/schema.ts
L135: Confidence: 40%
L136: - Evidence: `drizzle.config.ts:1` (hash: `1f5c93c3d974`)
L137: - Evidence: `server/db.ts:1` (hash: `3d66d6ea5af3`)
L138: 
L139: ## Verified: What the Target System Is
L140: 
L141: ### The project is named "rest-express" (from package.json)
L142: Confidence: 60%
L143: - Evidence: `package.json:2` (hash: `a1f1a980b4b8`)
L144: 
L145: ### Python project named "program-totality-analyzer" (from pyproject.toml)
L146: Confidence: 50%
L147: - Evidence: `pyproject.toml:2` (hash: `f0d4a96fe7d6`)
L148: 
L149: ## Verified Structural (deterministic extractors only)
L150: 
L151: - **dependencies**: not_implemented: requires lockfile parser (package-lock.json, requirements.txt, etc.)
L152: - **enforcement**: not_implemented: requires auth/middleware pattern detector over source files
L153: - **routes**: not_implemented: requires AST/regex route extractor over source files
L154: - **schemas**: not_implemented: requires migration/model file parser
L155: 
L156: ## Known Unknown Surface
L157: 
L158: | Category | Status | Notes |
L159: |----------|--------|-------|
L160: | tls_termination | UNKNOWN | No matching infrastructure/config artifacts found in file index |
L161: | encryption_at_rest | UNKNOWN | No matching infrastructure/config artifacts found in file index |
L162: | secret_management | UNKNOWN | No matching infrastructure/config artifacts found in file index |
L163: | deployment_topology | UNKNOWN | No matching infrastructure/config artifacts found in file index |
L164: | runtime_iam | UNKNOWN | No matching infrastructure/config artifacts found in file index |
L165: | logging_sink | UNKNOWN | No matching infrastructure/config artifacts found in file index |
L166: | monitoring_alerting | UNKNOWN | No matching infrastructure/config artifacts found in file index |
L167: | backup_retention | UNKNOWN | No matching infrastructure/config artifacts found in file index |
L168: | data_residency | UNKNOWN | No matching infrastructure/config artifacts found in file index |
L169: 
L170: ## Snippet Hashes (20 total)
L171: 
L172: - `020435ddf436`
L173: - `053150b640a7`
L174: - `05da5f1b1281`
L175: - `1005be19f14a`
L176: - `1d3dd608c3bb`
L177: - `1f5c93c3d974`
L178: - `1f70e6a77d42`
L179: - `2f87d29d3b03`
L180: - `3d66d6ea5af3`
L181: - `50c86b7ed8ac`
L182: - `550b970621c2`
L183: - `75d345a78f84`
L184: - `79d8bdf275d6`
L185: - `96fa2e5505e4`
L186: - `9b7206f3d09a`
L187: - `a19790628fbe`
L188: - `a1f1a980b4b8`
L189: - `f0d4a96fe7d6`
L190: - `f7eebadd079d`
L191: - `fd240a9dc053`

--- FILE: output/packs/docs_pack.txt ---
L1: 
L2: --- FILE: README.md ---
L3: L1: # Program Totality Analyzer
L4: L2: 
L5: L3: A static-artifact-anchored analysis tool that generates technical dossiers for software projects. It extracts what a system is, how to run it, what it needs, and what it cannot determine — with every claim citing `file:line` evidence backed by SHA-256 snippet hashes.
L6: L4: 
L7: L5: **Scope limitation:** PTA analyzes static artifacts only (source files, config, lockfiles). It does not observe runtime behavior, prove correctness, or guarantee security. Claims labeled VERIFIED mean "anchored to a hash-verified source snippet," not "proven true at runtime."
L8: L6: 
L9: L7: ## What It Does
L10: L8: 
L11: L9: Given a software project (GitHub repo, local folder, or Replit workspace), the analyzer produces:
L12: L10: 
L13: L11: | File | Contents |
L14: L12: |------|----------|
L15: L13: | `target_howto.json` | Operator manual: prerequisites, install steps, config, dev/prod run commands, Replit execution profile |
L16: L14: | `claims.json` | Verifiable claims about the system, each with file:line evidence and confidence scores |
L17: L15: | `coverage.json` | Scan metadata: files scanned, files skipped, Replit detection evidence |
L18: L16: | `replit_profile.json` | Replit-specific: port binding, secrets, external APIs, observability (only in Replit mode) |
L19: L17: | `DOSSIER.md` | Human-readable markdown dossier summarizing all findings |
L20: L18: | `index.json` | Full file index of scanned files |
L21: L19: | `packs/` | Evidence packs (docs, config, code, ops) used during analysis |
L22: L20: 
L23: L21: ## Install
L24: L22: 
L25: L23: ```bash
L26: L24: pip install -e .
L27: L25: ```
L28: L26: 
L29: L27: This registers the `pta` command. Alternatively, run as a module or directly:
L30: L28: 
L31: L29: ```bash
L32: L30: python -m server.analyzer.src --help
L33: L31: python server/analyzer/analyzer_cli.py --help
L34: L32: ```
L35: L33: 
L36: L34: ### Dependencies
L37: L35: 
L38: L36: - Python 3.11+
L39: L37: - Required packages: `typer`, `rich`, `openai`, `gitpython`, `jsonschema`, `python-dotenv`, `pydantic`
L40: L38: 
L41: L39: ## Usage
L42: L40: 
L43: L41: ### Three Modes
L44: L42: 
L45: L43: **GitHub repository:**
L46: L44: ```bash
L47: L45: pta analyze https://github.com/user/repo -o ./output
L48: L46: ```
L49: L47: 
L50: L48: **Local folder:**
L51: L49: ```bash
L52: L50: pta analyze ./path/to/project -o ./output
L53: L51: ```
L54: L52: 
L55: L53: **Replit workspace (run from inside the workspace):**
L56: L54: ```bash
L57: L55: pta analyze --replit -o ./output
L58: L56: ```
L59: L57: 
L60: L58: ### Deterministic Mode (`--no-llm`)
L61: L59: 
L62: L60: Skip all LLM calls and produce only deterministic, structurally-extracted outputs:
L63: L61: 
L64: L62: ```bash
L65: L63: pta analyze --replit --no-llm -o ./output
L66: L64: ```
L67: L65: 
L68: L66: This mode requires no API keys and produces reproducible results. It extracts:
L69: L67: - Package scripts (dev, build, start)
L70: L68: - Lockfile-based install commands
L71: L69: - Environment variable references (names only, never values)
L72: L70: - Port binding configuration
L73: L71: - External API usage
L74: L72: - Replit platform detection
L75: L73: 
L76: L74: ### With LLM Analysis
L77: L75: 
L78: L76: For semantic analysis (architecture understanding, risk assessment, integration patterns):
L79: L77: 
L80: L78: ```bash
L81: L79: pta analyze --replit -o ./output
L82: L80: ```
L83: L81: 
L84: L82: Requires `AI_INTEGRATIONS_OPENAI_API_KEY` and `AI_INTEGRATIONS_OPENAI_BASE_URL` environment variables.
L85: L83: 
L86: L84: ### Scoping a Subdirectory
L87: L85: 
L88: L86: ```bash
L89: L87: pta analyze https://github.com/user/monorepo --root packages/api -o ./output
L90: L88: ```
L91: L89: 
L92: L90: ## Evidence Model
L93: L91: 
L94: L92: Every claim in the output cites structured evidence:
L95: L93: 
L96: L94: ```json
L97: L95: {
L98: L96:   "path": "server/index.ts",
L99: L97:   "line_start": 92,
L100: L98:   "line_end": 92,
L101: L99:   "snippet_hash": "75d345a78f84",
L102: L100:   "display": "server/index.ts:92"
L103: L101: }
L104: L102: ```
L105: L103: 
L106: L104: - `path` -- file path relative to project root
L107: L105: - `line_start` / `line_end` -- 1-indexed line range (never 0)
L108: L106: - `snippet_hash` -- first 12 hex chars of SHA-256 of the stripped line(s)
L109: L107: - `display` -- human-readable location string
L110: L108: 
L111: L109: For file-existence evidence (e.g., lockfile detection):
L112: L110: 
L113: L111: ```json
L114: L112: {
L115: L113:   "kind": "file_exists",
L116: L114:   "path": "package-lock.json",
L117: L115:   "snippet_hash": "053150b640a7",
L118: L116:   "display": "package-lock.json (file exists)"
L119: L117: }
L120: L118: ```
L121: L119: 
L122: L120: ### Verification
L123: L121: 
L124: L122: Snippet hashes are re-checked against source files: the analyzer re-reads the cited line range, strips whitespace, hashes the result, and confirms it matches the claimed hash. Claims that fail hash verification are capped at confidence 0.20 and marked `"status": "unverified"`.
L125: L123: 
L126: L124: **Important:** Hash verification confirms that a snippet exists at the cited location. It does not prove that the code behaves as described, is secure, or is free of bugs. PTA is not a security scanner, compliance certification tool, or correctness prover.
L127: L125: 
L128: L126: ### Whitespace Policy
L129: L127: 
L130: L128: Lines are stripped (trimmed) before hashing. This normalizes indentation differences across editors and formatters. Both evidence creation and verification use the same canonicalization.
L131: L129: 
L132: L130: ## Security
L133: L131: 
L134: L132: - **Symlink protection**: Every path component is checked. If any component in the path tree is a symlink, the file is rejected.
L135: L133: - **Path containment**: All resolved paths must remain within the project root (`relative_to()` check after `resolve()`).
L136: L134: - **Binary detection**: Null bytes in the first 4KB trigger rejection before text decoding.
L137: L135: - **Traversal prevention**: `..` segments and absolute paths are rejected.
L138: L136: - **Secret safety**: Only environment variable names are extracted, never their values.
L139: L137: - **Self-skip**: The analyzer excludes its own source files from analysis to prevent false-positive pattern matches.
L140: L138: 
L141: L139: ## Output Files
L142: L140: 
L143: L141: ### `target_howto.json`
L144: L142: 
L145: L143: Operator manual with:
L146: L144: - `prereqs` -- required runtimes
L147: L145: - `install_steps` -- with commands and evidence
L148: L146: - `config` -- environment variables with file:line references
L149: L147: - `run_dev` / `run_prod` -- start commands with evidence
L150: L148: - `replit_execution_profile` -- port binding, secrets, external APIs (Replit mode)
L151: L149: - `unknowns` -- things the analyzer could not determine
L152: L150: - `completeness` -- scoring with missing items
L153: L151: 
L154: L152: ### `claims.json`
L155: L153: 
L156: L154: Array of verifiable claims:
L157: L155: - `statement` -- what is claimed
L158: L156: - `confidence` -- 0.0 to 1.0
L159: L157: - `evidence` -- array of evidence objects with `snippet_hash_verified: true/false`
L160: L158: - `status` -- `"evidenced"` or `"unverified"`
L161: L159: 
L162: L160: ### `coverage.json`
L163: L161: 
L164: L162: - `mode_requested` / `mode` -- analysis mode
L165: L163: - `scanned` / `skipped` -- file counts
L166: L164: - `replit_detected` -- boolean
L167: L165: - `replit_detection_evidence` -- evidence for Replit detection
L168: L166: - `self_skip` -- analyzer self-exclusion details
L169: L167: 
L170: L168: ## Troubleshooting
L171: L169: 
L172: L170: ### "No module named 'core'"
L173: L171: 
L174: L172: Run from the repo root, or install with `pip install -e .`
L175: L173: 
L176: L174: ### Missing `DATABASE_URL`
L177: L175: 
L178: L176: The analyzer itself does not need a database. `DATABASE_URL` appears in outputs because it detects the target project's database configuration. No action needed for the analyzer.
L179: L177: 
L180: L178: ### Missing OpenAI environment variables
L181: L179: 
L182: L180: Only required when running without `--no-llm`. Set:
L183: L181: ```bash
L184: L182: export AI_INTEGRATIONS_OPENAI_API_KEY=your-key
L185: L183: export AI_INTEGRATIONS_OPENAI_BASE_URL=https://api.openai.com/v1
L186: L184: ```
L187: L185: 
L188: L186: ### "Port already in use"
L189: L187: 
L190: L188: The analyzer does not bind any ports. If you see port errors, they come from the target project's web server, not the analyzer.
L191: L189: 
L192: L190: ## Architecture
L193: L191: 
L194: L192: Two strictly separated layers:
L195: L193: 
L196: L194: 1. **Structural layer** (deterministic) — file indexing, pattern matching, evidence extraction. Outputs are reproducible and hash-verified against source artifacts.
L197: L195: 2. **Semantic layer** (LLM-powered, optional) — architecture interpretation, risk assessment, integration analysis. Outputs are labeled as LLM-generated and carry confidence scores, not deterministic guarantees.
L198: L196: 
L199: L197: The `--no-llm` flag gives you only the structural layer. The semantic layer adds interpretation but is namespaced separately and never contaminates structural evidence.
L200: L198: 
L201: L199: ## Running Tests
L202: L200: 
L203: L201: ```bash
L204: L202: bash scripts/smoke_test.sh
L205: L203: ```
L206: L204: 
L207: L205: ## License
L208: L206: 
L209: L207: MIT
L210: 
L211: --- FILE: replit.md ---
L212: L1: # Overview
L213: L2: 
L214: L3: **Program Totality Analyzer** — a full-stack web application that ingests software projects (via GitHub URL, local path, or live Replit workspace) and produces evidence-cited technical dossiers. The dossier covers what a target system is, how it works, how to use it, and what risks/unknowns exist. It combines a React frontend for submitting analysis requests and viewing results with an Express backend that manages projects/analyses in PostgreSQL and spawns a Python-based analyzer CLI for the actual code analysis.
L215: L4: 
L216: L5: ## User Preferences
L217: L6: 
L218: L7: Preferred communication style: Simple, everyday language.
L219: L8: 
L220: L9: ## System Architecture
L221: L10: 
L222: L11: ### Monorepo Structure
L223: L12: 
L224: L13: The project follows a three-zone monorepo pattern:
L225: L14: 
L226: L15: - **`client/`** — React SPA (frontend)
L227: L16: - **`server/`** — Express API (backend)
L228: L17: - **`shared/`** — Shared types, schemas, and route definitions used by both client and server
L229: L18: 
L230: L19: This avoids type drift between frontend and backend by sharing Zod schemas and TypeScript types from a single source of truth.
L231: L20: 
L232: L21: ### Frontend (`client/src/`)
L233: L22: 
L234: L23: - **Framework**: React 18 with TypeScript
L235: L24: - **Routing**: Wouter (lightweight client-side router)
L236: L25: - **State/Data Fetching**: TanStack React Query with polling for analysis status updates
L237: L26: - **UI Components**: shadcn/ui (new-york style) built on Radix UI primitives
L238: L27: - **Styling**: Tailwind CSS with CSS variables for theming (dark mode, cyan/neon aesthetic)
L239: L28: - **Animations**: Framer Motion for page transitions and loading states
L240: L29: - **Markdown Rendering**: react-markdown for displaying analysis dossiers
L241: L30: - **Build Tool**: Vite with React plugin
L242: L31: 
L243: L32: Key pages:
L244: L33: - `/` — Home page with URL input form and "Analyze Replit" button
L245: L34: - `/projects` — List of previous analyses
L246: L35: - `/projects/:id` — Detailed view of a specific analysis with tabs for dossier, claims, operator dashboard (operate.json), coverage, and unknowns
L247: L36: 
L248: L37: Path aliases: `@/` maps to `client/src/`, `@shared/` maps to `shared/`, `@assets/` maps to `attached_assets/`.
L249: L38: 
L250: L39: ### Backend (`server/`)
L251: L40: 
L252: L41: - **Framework**: Express 5 on Node.js
L253: L42: - **Language**: TypeScript, run via `tsx` in dev
L254: L43: - **API Pattern**: REST API under `/api/` prefix, route definitions shared via `shared/routes.ts`
L255: L44: - **Dev Server**: Vite middleware in development (HMR via `server/vite.ts`), static file serving in production (`server/static.ts`)
L256: L45: - **Build**: esbuild bundles server to `dist/index.cjs`; Vite builds client to `dist/public/`
L257: L46: 
L258: L47: Key API routes (defined in `server/routes.ts`):
L259: L48: - `GET /api/projects` — List all projects
L260: L49: - `POST /api/projects` — Create a new project (with mode: github/local/replit)
L261: L50: - `GET /api/projects/:id` — Get project details
L262: L51: - `GET /api/projects/:id/analysis` — Get analysis results
L263: L52: - `POST /api/projects/:id/analyze` — Trigger analysis (spawns Python CLI)
L264: L53: 
L265: L54: ### Python Analyzer (`server/analyzer/`)
L266: L55: 
L267: L56: - **CLI**: `analyzer_cli.py` using Typer, supports three input modes:
L268: L57:   - GitHub URL (`analyze <url>`)
L269: L58:   - Local path (`analyze <path>`)
L270: L59:   - Replit workspace (`analyze --replit`)
L271: L60: - **Core**: `server/analyzer/src/analyzer.py` — orchestrates file acquisition, indexing, and LLM-powered analysis
L272: L61: - **Operate Module**: `server/analyzer/src/core/operate.py` — deterministic (no LLM) extraction of operational data into `operate.json`
L273: L62:   - Extracts boot commands, ports, integration points (endpoints, env vars, auth), deployment config, and runbook steps
L274: L63:   - Uses three evidence tiers: EVIDENCED (file:line + SHA-256 snippet hash), INFERRED, UNKNOWN (with unknown_reason)
L275: L64:   - Computes readiness scores (0-100) for boot, integrate, deploy categories
L276: L65:   - Identifies operational gaps with severity ratings
L277: L66: - **LLM Integration**: OpenAI API (via Replit AI Integrations env vars: `AI_INTEGRATIONS_OPENAI_API_KEY`, `AI_INTEGRATIONS_OPENAI_BASE_URL`)
L278: L67: - The Express server spawns the Python analyzer as a child process
L279: L68: 
L280: L69: ### Database
L281: L70: 
L282: L71: - **Engine**: PostgreSQL (required, referenced via `DATABASE_URL` env var)
L283: L72: - **ORM**: Drizzle ORM with `drizzle-zod` for schema-to-Zod validation
L284: L73: - **Schema** (`shared/schema.ts`):
L285: L74:   - `projects` — id, url, name, mode (github/local/replit), status (pending/analyzing/completed/failed), createdAt
L286: L75:   - `analyses` — id, projectId, dossier (markdown text), claims (jsonb), howto (jsonb), coverage (jsonb), unknowns (jsonb), operate (jsonb), createdAt
L287: L76: - **Chat models** (`shared/models/chat.ts`):
L288: L77:   - `conversations` — id, title, createdAt
L289: L78:   - `messages` — id, conversationId, role, content, createdAt
L290: L79: - **Migrations**: Drizzle Kit with `drizzle-kit push` for schema sync
L291: L80: - **Storage Layer**: `server/storage.ts` implements `IStorage` interface with `DatabaseStorage` class
L292: L81: 
L293: L82: ### Replit Integrations (`server/replit_integrations/` and `client/replit_integrations/`)
L294: L83: 
L295: L84: Pre-built integration modules for AI features:
L296: L85: - **Chat** — Text-based conversation routes and storage using OpenAI
L297: L86: - **Audio** — Voice recording, playback, speech-to-text, text-to-speech with AudioWorklet
L298: L87: - **Image** — Image generation and editing via `gpt-image-1`
L299: L88: - **Batch** — Rate-limited batch processing with retries for LLM calls
L300: L89: 
L301: L90: These are utility modules that can be registered on the Express app as needed.
L302: L91: 
L303: L92: ### Key Design Decisions
L304: L93: 
L305: L94: 1. **Shared route definitions** — `shared/routes.ts` defines API contracts (paths, input schemas, response schemas) used by both frontend hooks and backend handlers. This ensures type safety across the stack.
L306: L95: 
L307: L96: 2. **Python + Node hybrid** — The analyzer logic lives in Python (better ecosystem for code analysis, rich CLI output) while the web layer is Node/Express. The server spawns Python as a child process rather than using a microservice architecture, keeping deployment simple.
L308: L97: 
L309: L98: 3. **Evidence-first analysis** — The analyzer is designed to cite file paths and line ranges for every claim. When evidence is missing, it must label findings as inference/unknown rather than hallucinate.
L310: L99: 
L311: L100: 4. **Polling for status** — The frontend polls project status every 2 seconds while analysis is in progress, switching to static once completed/failed.
L312: L101: 
L313: L102: ## External Dependencies
L314: L103: 
L315: L104: ### Required Services
L316: L105: - **PostgreSQL** — Primary database, must be provisioned with `DATABASE_URL` environment variable
L317: L106: - **OpenAI API** (via Replit AI Integrations) — Powers the code analysis LLM calls
L318: L107:   - `AI_INTEGRATIONS_OPENAI_API_KEY` — API key
L319: L108:   - `AI_INTEGRATIONS_OPENAI_BASE_URL` — Base URL for API
L320: L109: 
L321: L110: ### Key NPM Packages
L322: L111: - `express` v5 — HTTP server
L323: L112: - `drizzle-orm` + `drizzle-kit` — Database ORM and migrations
L324: L113: - `@tanstack/react-query` — Client-side data fetching and caching
L325: L114: - `wouter` — Client-side routing
L326: L115: - `react-markdown` — Markdown rendering for dossiers
L327: L116: - `framer-motion` — Animations
L328: L117: - `zod` + `drizzle-zod` — Runtime validation
L329: L118: - `vite` — Frontend build and dev server
L330: L119: - `esbuild` — Server build
L331: L120: 
L332: L121: ### Key Python Packages
L333: L122: - `typer` — CLI framework
L334: L123: - `openai` — LLM API client
L335: L124: - `rich` — Console output formatting
L336: L125: - `python-dotenv` — Environment variable loading
L337: L126: 
L338: L127: ### Dev/Build Tools
L339: L128: - `tsx` — TypeScript execution for development
L340: L129: - `tailwindcss` + `postcss` + `autoprefixer` — CSS toolchain
L341: L130: - `@replit/vite-plugin-runtime-error-modal` — Dev error overlay
L342: 
L343: --- FILE: client/requirements.md ---
L344: L1: ## Packages
L345: L2: react-markdown | For rendering the analysis dossier
L346: L3: framer-motion | For smooth page transitions and loading effects
L347: L4: clsx | Utility for constructing className strings conditionally
L348: L5: tailwind-merge | Utility for merging Tailwind classes efficiently
L349: L6: 
L350: L7: ## Notes
L351: L8: - Theme: Technical, dark mode, "Program Totality Analyzer" aesthetic.
L352: L9: - Fonts: Space Grotesk (headers), JetBrains Mono (code/data), Inter (UI).
L353: L10: - Polling: Project status needs polling to show "Analyzing..." vs "Completed".
L354: 
L355: --- FILE: examples/README.md ---
L356: L1: # Example Outputs
L357: L2: 
L358: L3: These are sample outputs from the Program Totality Analyzer running in `--no-llm` (deterministic) mode against its own workspace.
L359: L4: 
L360: L5: ## Files
L361: L6: 
L362: L7: - `out/target_howto.sample.json` — Operator manual: install steps, config, run commands, Replit execution profile. Every item cites file:line evidence with SHA-256 snippet hashes.
L363: L8: - `out/coverage.sample.json` — Scan metadata: mode requested, files scanned/skipped, Replit detection evidence, self-skip configuration.
L364: L9: 
L365: L10: ## Generating Your Own
L366: L11: 
L367: L12: ```bash
L368: L13: pta analyze --replit --no-llm -o ./my_output
L369: L14: ```
L370: L15: 
L371: L16: Or for a GitHub repo:
L372: L17: 
L373: L18: ```bash
L374: L19: pta analyze https://github.com/user/repo -o ./my_output
L375: L20: ```
L376: L21: 
L377: L22: Or for a local folder:
L378: L23: 
L379: L24: ```bash
L380: L25: pta analyze ./path/to/project -o ./my_output
L381: L26: ```
L382: 
L383: --- FILE: docs/dossiers/lantern_program_totality_dossier.md ---
L384: L1: ---
L385: L2: title: Lantern Program Totality Dossier
L386: L3: generated_by: PTA / Lantern
L387: L4: mode: deterministic+curated
L388: L5: date: 2026-02-14
L389: L6: ---
L390: L7: 
L391: L8: # HALO-RECEIPTS: Program Totality Analyzer Dossier
L392: L9: 
L393: L10: ---
L394: L11: 
L395: L12: ## 1. **Identity of Target System**
L396: L13: 
L397: L14: **What it IS:**  
L398: L15: HALO-RECEIPTS (AI Receipts) is a forensic verification system specifically designed for AI conversation transcripts. It provides cryptographic verification (SHA-256, Ed25519), immutable receipt storage, tamper-evident audit trails, forensic export capabilities, and extensive auditing for post-hoc analysis. This system is both the backend API server (Node.js/Express/PostgreSQL/Drizzle ORM) and a modern React UI, bundling forensic guarantees directly into receipt management and export (README.md:3,9,60–61; replit.md:4,11–12,14–24).
L399: L16: 
L400: L17: **What it is NOT:**  
L401: L18: - **Not a real-time monitoring, content moderation, or multi-operator platform:** It is not designed for live chat moderation, direct truth judgment, or multi-user concurrency at the enforcement level (replit.md:55).
L402: L19: - **Not a database engine:** Instead, it relies on PostgreSQL for durable state.
L403: L20: - **Not a data lake or generic file archival platform.**
L404: L21: - **Not a replacement for WORM-compliant log systems, but can integrate via checkpoint anchoring (see below).**
L405: L22: - **Not a deployment framework:** The system expects to be deployed behind a reverse proxy or PaaS (README.md:24; SECURITY.md:54).
L406: L23: 
L407: L24: ---
L408: L25: 
L409: L26: ## 2. **Purpose & Jobs-to-be-done**
L410: L27: 
L411: L28: - **Forensic Conversation Integrity:** Operators can guarantee, via public proofs, that a transcript or "receipt" has not been tampered with since its recording date (README.md:9; replit.md:4).
L412: L29: - **Immutable Logging & Audit Trails:** Ensures all receipt actions (append, lock, kill switch, export, audit actions) are tracked in an append-only, hash-linked audit log, detecting insertions, deletions, reordering, and version tampering (SECURITY.md:8–10; STATE.md:165–169).
L413: L30: - **Cryptographic Verification:** Verifies that every receipt chain and audit log entry is both hash-linked (SHA-256) and checkpoint signed (Ed25519), with optional external anchoring (replit.md:36–46; STATE.md:116–121).
L414: L31: - **Forensic Export and Proof Packs:** Allows export of forensic packs (JSON) that can be offline verified and admitted as tamper-evident evidence (STATE.md:122–125; scripts/ci-forensic-gate.sh).
L415: L32: - **Regulatory Alignment:** System features mapped to compliance goals (21 CFR, HIPAA, SOC2, etc.) (replit.md:50, STATE.md:137).
L416: L33: - **Operator/Evidence Reliability:** Designed to provide demonstrable evidence for courts, regulators, or internal review.
L417: L34: 
L418: L35: ---
L419: L36: 
L420: L37: ## 3. **Capability Map**
L421: L38: 
L422: L39: | Capability             | Mechanism / Implementation | Evidence                                    |
L423: L40: |------------------------|---------------------------|---------------------------------------------|
L424: L41: | SHA-256 Hash Verification   | Canonicalized (c14n-v1) JSON hash | README.md:73–74; STATE.md:17,20             |
L425: L42: | Ed25519 Signatures     | Checkpoint signing, chain   | STATE.md:18,116–121; replit.md:36           |
L426: L43: | Immutable Storage      | Receipt lock, no mutation  | README.md:75; STATE.md:21,158–159           |
L427: L44: | Kill Switch            | Irreversible flag, disables outputs | README.md:76; STATE.md:22,157                |
L428: L45: | Audit Logs             | Append-only, hash-chained table | STATE.md:25–29,162                           |
L429: L46: | Forensic Export/Import | export_forensic_pack, verify_forensic_pack scripts | STATE.md:123–126                              |
L430: L47: | Forensic Sensors       | Interpreter, summarizer, claim extractor | README.md:78; STATE.md:80,85                  |
L431: L48: | Policy Enforcement     | Zod schemas, request shape limits | SECURITY.md:20–23                            |
L432: L49: | API Rate Limiting      | Per-IP, in-memory          | SECURITY.md:26–29; STATE.md:94; package.json:61 |
L433: L50: | Key Rotation & Anchoring | Multi-key support, anchor backends | replit.md:43–47                            |
L434: L51: | Secure API Structure   | API_KEY in x-api-key header; private/public endpoints | SECURITY.md:15–16,72                           |
L435: L52: | Client Auth Isolation  | LLMs see only transcript content | SECURITY.md:39–40; STATE.md:160,20           |
L436: L53: | UI Export & Compare    | Side-by-side comparison, JSONL/CSV export | README.md:143; replit.md:25,23                |
L437: L54: | Structured Logging     | JSON logs, in-memory counters | STATE.md:106–107,184                          |
L438: L55: | Health Checks          | /api/health, /api/ready    | STATE.md:37,43,100–101; docs/API_CONTRACTS.md:11,24 |
L439: L56: 
L440: L57: ---
L441: L58: 
L442: L59: ## 4. **Architecture Snapshot**
L443: L60: 
L444: L61: - **Frontend:** React (wouter router), Tailwind, shadcn/ui (README.md:59, client/src/App.tsx)
L445: L62: - **Backend:** Node.js 20, Express, Drizzle ORM (README.md:60–61; package.json)
L446: L63: - **Database:** PostgreSQL 14+ (README.md:24, .env.example:5)
L447: L64: - **Cryptography:** Node.js crypto (SHA-256), Ed25519 (STATE.md:18,116)
L448: L65: - **Session:** express-session, connect-pg-simple (package.json:51,57)
L449: L66: - **Audit Trail:** Hash-linking via prev_hash and payload_v, audit_head singleton row (STATE.md:9,25–29,48,52; drizzle.config.ts:9)
L450: L67: - **Forensic Export:** TypeScript scripts in `/scripts`, results in JSON proof packs (STATE.md:123–126)
L451: L68: - **CI/CD:** GitHub Actions, drift guard scripts, reproducible verifier zips (replit.md:39–42,57)
L452: L69: 
L453: L70: ---
L454: L71: 
L455: L72: ## 5. **How to Use the Target System**
L456: L73: 
L457: L74: ### **Operator Manual**
L458: L75: 
L459: L76: #### **A. Prerequisites**
L460: L77: 
L461: L78: 1. **Install:**
L462: L79:    - Node.js 20+, npm (`npm -v`/`node -v`)
L463: L80:    - PostgreSQL 14+ running and accessible (README.md:23–24)
L464: L81:    - jq, unzip, python3 for export/ops scripts (see replit.nix, scripts/ci-forensic-gate.sh)
L465: L82:    - TypeScript, tsx, drizzle-kit, installed via npm as devDependencies (package.json)
L466: L83: 
L467: L84: #### **B. Installation**
L468: L85: 
L469: L86: 1. **Clone Repository**
L470: L87: 2. `npm install`  
L471: L88:    Installs all dependencies (README.md:29)
L472: L89: 3. `cp .env.example .env`  
L473: L90:    Copy template env config (README.md:33)
L474: L91: 4. **Edit `.env`**:  
L475: L92:    Set `DATABASE_URL`, `API_KEY`, `SESSION_SECRET` and all other required variables suitably (README.md:34; .env.example:5,10,23)
L476: L93: 5. **(Optional: Replit):**
L477: L94:    - Use the "Run on Replit" badge or Replit sidebar GUI (README.md:17)
L478: L95: 
L479: L96: #### **C. Configuration**
L480: L97: 
L481: L98: Set the following in `.env` (names only, do not provide values):
L482: L99: - **DATABASE_URL:** PostgreSQL connection string (.env.example:5)
L483: L100: - **API_KEY:** Required for private endpoints (.env.example:10; SECURITY.md:15)
L484: L101: - **SESSION_SECRET:** Strong, random string (.env.example:23; SECURITY.md:71)
L485: L102: - **NODE_ENV:** development/production (.env.example:13)
L486: L103: - **PORT:** Default 5000 (.env.example:14)
L487: L104: - Other optional: TRANSCRIPT_MODE, CHECKPOINT_INTERVAL, CHECKPOINT_ANCHOR_TYPE, etc. (.env.example, STATE.md:118, replit.md:45)
L488: L105: 
L489: L106: #### **D. Database Init**
L490: L107: 
L491: L108: - Run: `npm run db:push`  
L492: L109:   This applies the schema to PostgreSQL (README.md:39)
L493: L110: 
L494: L111: #### **E. Development Server**
L495: L112: 
L496: L113: - Run: `npm run dev`  
L497: L114:   Runs server in development mode (README.md:44)
L498: L115: - Visit: [http://localhost:5000](http://localhost:5000) (README.md:47)
L499: L116: 
L500: L117: #### **F. Production Build**

--- FILE: .pytest_cache/README.md ---
L1: # pytest cache directory #
L2: 
L3: This directory contains data from the pytest's cache plugin,
L4: which provides the `--lf` and `--ff` options, as well as the `cache` fixture.
L5: 
L6: **Do not** commit this to version control.
L7: 
L8: See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.
