
--- FILE: components.json ---
L1: {
L2:     "$schema": "https://ui.shadcn.com/schema.json",
L3:     "style": "new-york",
L4:     "rsc": false,
L5:     "tsx": true,
L6:     "tailwind": {
L7:       "config": "tailwind.config.ts",
L8:       "css": "client/src/index.css",
L9:       "baseColor": "neutral",
L10:       "cssVariables": true,
L11:       "prefix": ""
L12:     },
L13:     "aliases": {
L14:       "components": "@/components",
L15:       "utils": "@/lib/utils",
L16:       "ui": "@/components/ui",
L17:       "lib": "@/lib",
L18:       "hooks": "@/hooks"
L19:     }
L20: }

--- FILE: package-lock.json ---
L1: {
L2:   "name": "rest-express",
L3:   "version": "1.0.0",
L4:   "lockfileVersion": 3,
L5:   "requires": true,
L6:   "packages": {
L7:     "": {
L8:       "name": "rest-express",
L9:       "version": "1.0.0",
L10:       "license": "MIT",
L11:       "dependencies": {
L12:         "@hookform/resolvers": "^3.10.0",
L13:         "@jridgewell/trace-mapping": "^0.3.25",
L14:         "@radix-ui/react-accordion": "^1.2.4",
L15:         "@radix-ui/react-alert-dialog": "^1.1.7",
L16:         "@radix-ui/react-aspect-ratio": "^1.1.3",
L17:         "@radix-ui/react-avatar": "^1.1.4",
L18:         "@radix-ui/react-checkbox": "^1.1.5",
L19:         "@radix-ui/react-collapsible": "^1.1.4",
L20:         "@radix-ui/react-context-menu": "^2.2.7",
L21:         "@radix-ui/react-dialog": "^1.1.7",
L22:         "@radix-ui/react-dropdown-menu": "^2.1.7",
L23:         "@radix-ui/react-hover-card": "^1.1.7",
L24:         "@radix-ui/react-label": "^2.1.3",
L25:         "@radix-ui/react-menubar": "^1.1.7",
L26:         "@radix-ui/react-navigation-menu": "^1.2.6",
L27:         "@radix-ui/react-popover": "^1.1.7",
L28:         "@radix-ui/react-progress": "^1.1.3",
L29:         "@radix-ui/react-radio-group": "^1.2.4",
L30:         "@radix-ui/react-scroll-area": "^1.2.4",
L31:         "@radix-ui/react-select": "^2.1.7",
L32:         "@radix-ui/react-separator": "^1.1.3",
L33:         "@radix-ui/react-slider": "^1.2.4",
L34:         "@radix-ui/react-slot": "^1.2.0",
L35:         "@radix-ui/react-switch": "^1.1.4",
L36:         "@radix-ui/react-tabs": "^1.1.4",
L37:         "@radix-ui/react-toast": "^1.2.7",
L38:         "@radix-ui/react-toggle": "^1.1.3",
L39:         "@radix-ui/react-toggle-group": "^1.1.3",
L40:         "@radix-ui/react-tooltip": "^1.2.0",
L41:         "@tanstack/react-query": "^5.60.5",
L42:         "class-variance-authority": "^0.7.1",
L43:         "clsx": "^2.1.1",
L44:         "cmdk": "^1.1.1",
L45:         "connect-pg-simple": "^10.0.0",
L46:         "date-fns": "^3.6.0",
L47:         "drizzle-orm": "^0.39.3",
L48:         "drizzle-zod": "^0.7.1",
L49:         "embla-carousel-react": "^8.6.0",
L50:         "express": "^5.0.1",
L51:         "express-session": "^1.18.1",
L52:         "framer-motion": "^11.18.2",
L53:         "input-otp": "^1.4.2",
L54:         "lucide-react": "^0.453.0",
L55:         "memorystore": "^1.6.7",
L56:         "next-themes": "^0.4.6",
L57:         "openai": "^6.22.0",
L58:         "p-limit": "^7.3.0",
L59:         "p-retry": "^7.1.1",
L60:         "passport": "^0.7.0",
L61:         "passport-local": "^1.0.0",
L62:         "pg": "^8.16.3",
L63:         "react": "^18.3.1",
L64:         "react-day-picker": "^8.10.1",
L65:         "react-dom": "^18.3.1",
L66:         "react-hook-form": "^7.55.0",
L67:         "react-icons": "^5.4.0",
L68:         "react-markdown": "^10.1.0",
L69:         "react-resizable-panels": "^2.1.7",
L70:         "recharts": "^2.15.2",
L71:         "tailwind-merge": "^2.6.1",
L72:         "tailwindcss-animate": "^1.0.7",
L73:         "tw-animate-css": "^1.2.5",
L74:         "vaul": "^1.1.2",
L75:         "wouter": "^3.3.5",
L76:         "ws": "^8.18.0",
L77:         "zod": "^3.25.76",
L78:         "zod-validation-error": "^3.5.4"
L79:       },
L80:       "devDependencies": {
L81:         "@replit/vite-plugin-cartographer": "^0.4.4",
L82:         "@replit/vite-plugin-dev-banner": "^0.1.1",
L83:         "@replit/vite-plugin-runtime-error-modal": "^0.0.3",
L84:         "@tailwindcss/typography": "^0.5.15",
L85:         "@tailwindcss/vite": "^4.1.18",
L86:         "@types/connect-pg-simple": "^7.0.3",
L87:         "@types/express": "^5.0.0",
L88:         "@types/express-session": "^1.18.0",
L89:         "@types/node": "20.19.27",
L90:         "@types/passport": "^1.0.16",
L91:         "@types/passport-local": "^1.0.38",
L92:         "@types/react": "^18.3.11",
L93:         "@types/react-dom": "^18.3.1",
L94:         "@types/ws": "^8.5.13",
L95:         "@vitejs/plugin-react": "^4.7.0",
L96:         "autoprefixer": "^10.4.20",
L97:         "drizzle-kit": "^0.31.8",
L98:         "esbuild": "^0.25.0",
L99:         "postcss": "^8.4.47",
L100:         "tailwindcss": "^3.4.17",
L101:         "tsx": "^4.20.5",
L102:         "typescript": "5.6.3",
L103:         "vite": "^7.3.0"
L104:       },
L105:       "optionalDependencies": {
L106:         "bufferutil": "^4.0.8"
L107:       }
L108:     },
L109:     "node_modules/@alloc/quick-lru": {
L110:       "version": "5.2.0",
L111:       "resolved": "https://registry.npmjs.org/@alloc/quick-lru/-/quick-lru-5.2.0.tgz",
L112:       "integrity": "sha512-UrcABB+4bUrFABwbluTIBErXwvbsU/V7TZWfmbgJfbkwiBuziS9gxdODUyuiecfdGQ85jglMW6juS3+z5TsKLw==",
L113:       "license": "MIT",
L114:       "engines": {
L115:         "node": ">=10"
L116:       },
L117:       "funding": {
L118:         "url": "https://github.com/sponsors/sindresorhus"
L119:       }
L120:     },
L121:     "node_modules/@babel/code-frame": {
L122:       "version": "7.27.1",
L123:       "resolved": "https://registry.npmjs.org/@babel/code-frame/-/code-frame-7.27.1.tgz",
L124:       "integrity": "sha512-cjQ7ZlQ0Mv3b47hABuTevyTuYN4i+loJKGeV9flcCgIK37cCXRh+L1bd3iBHlynerhQ7BhCkn2BPbQUL+rGqFg==",
L125:       "dev": true,
L126:       "license": "MIT",
L127:       "dependencies": {
L128:         "@babel/helper-validator-identifier": "^7.27.1",
L129:         "js-tokens": "^4.0.0",
L130:         "picocolors": "^1.1.1"
L131:       },
L132:       "engines": {
L133:         "node": ">=6.9.0"
L134:       }
L135:     },
L136:     "node_modules/@babel/compat-data": {
L137:       "version": "7.28.4",
L138:       "resolved": "https://registry.npmjs.org/@babel/compat-data/-/compat-data-7.28.4.tgz",
L139:       "integrity": "sha512-YsmSKC29MJwf0gF8Rjjrg5LQCmyh+j/nD8/eP7f+BeoQTKYqs9RoWbjGOdy0+1Ekr68RJZMUOPVQaQisnIo4Rw==",
L140:       "dev": true,
L141:       "license": "MIT",
L142:       "engines": {
L143:         "node": ">=6.9.0"
L144:       }
L145:     },
L146:     "node_modules/@babel/core": {
L147:       "version": "7.28.4",
L148:       "resolved": "https://registry.npmjs.org/@babel/core/-/core-7.28.4.tgz",
L149:       "integrity": "sha512-2BCOP7TN8M+gVDj7/ht3hsaO/B/n5oDbiAyyvnRlNOs+u1o+JWNYTQrmpuNp1/Wq2gcFrI01JAW+paEKDMx/CA==",
L150:       "dev": true,
L151:       "license": "MIT",
L152:       "dependencies": {
L153:         "@babel/code-frame": "^7.27.1",
L154:         "@babel/generator": "^7.28.3",
L155:         "@babel/helper-compilation-targets": "^7.27.2",
L156:         "@babel/helper-module-transforms": "^7.28.3",
L157:         "@babel/helpers": "^7.28.4",
L158:         "@babel/parser": "^7.28.4",
L159:         "@babel/template": "^7.27.2",
L160:         "@babel/traverse": "^7.28.4",
L161:         "@babel/types": "^7.28.4",
L162:         "@jridgewell/remapping": "^2.3.5",
L163:         "convert-source-map": "^2.0.0",
L164:         "debug": "^4.1.0",
L165:         "gensync": "^1.0.0-beta.2",
L166:         "json5": "^2.2.3",
L167:         "semver": "^6.3.1"
L168:       },
L169:       "engines": {
L170:         "node": ">=6.9.0"
L171:       },
L172:       "funding": {
L173:         "type": "opencollective",
L174:         "url": "https://opencollective.com/babel"
L175:       }
L176:     },
L177:     "node_modules/@babel/generator": {
L178:       "version": "7.28.3",
L179:       "resolved": "https://registry.npmjs.org/@babel/generator/-/generator-7.28.3.tgz",
L180:       "integrity": "sha512-3lSpxGgvnmZznmBkCRnVREPUFJv2wrv9iAoFDvADJc0ypmdOxdUtcLeBgBJ6zE0PMeTKnxeQzyk0xTBq4Ep7zw==",
L181:       "dev": true,
L182:       "license": "MIT",
L183:       "dependencies": {
L184:         "@babel/parser": "^7.28.3",
L185:         "@babel/types": "^7.28.2",
L186:         "@jridgewell/gen-mapping": "^0.3.12",
L187:         "@jridgewell/trace-mapping": "^0.3.28",
L188:         "jsesc": "^3.0.2"
L189:       },
L190:       "engines": {
L191:         "node": ">=6.9.0"
L192:       }
L193:     },
L194:     "node_modules/@babel/helper-compilation-targets": {
L195:       "version": "7.27.2",
L196:       "resolved": "https://registry.npmjs.org/@babel/helper-compilation-targets/-/helper-compilation-targets-7.27.2.tgz",
L197:       "integrity": "sha512-2+1thGUUWWjLTYTHZWK1n8Yga0ijBz1XAhUXcKy81rd5g6yh7hGqMp45v7cadSbEHc9G3OTv45SyneRN3ps4DQ==",
L198:       "dev": true,
L199:       "license": "MIT",
L200:       "dependencies": {
L201:         "@babel/compat-data": "^7.27.2",
L202:         "@babel/helper-validator-option": "^7.27.1",
L203:         "browserslist": "^4.24.0",
L204:         "lru-cache": "^5.1.1",
L205:         "semver": "^6.3.1"
L206:       },
L207:       "engines": {
L208:         "node": ">=6.9.0"
L209:       }
L210:     },
L211:     "node_modules/@babel/helper-globals": {
L212:       "version": "7.28.0",
L213:       "resolved": "https://registry.npmjs.org/@babel/helper-globals/-/helper-globals-7.28.0.tgz",
L214:       "integrity": "sha512-+W6cISkXFa1jXsDEdYA8HeevQT/FULhxzR99pxphltZcVaugps53THCeiWA8SguxxpSp3gKPiuYfSWopkLQ4hw==",
L215:       "dev": true,
L216:       "license": "MIT",
L217:       "engines": {
L218:         "node": ">=6.9.0"
L219:       }
L220:     },
L221:     "node_modules/@babel/helper-module-imports": {
L222:       "version": "7.27.1",
L223:       "resolved": "https://registry.npmjs.org/@babel/helper-module-imports/-/helper-module-imports-7.27.1.tgz",
L224:       "integrity": "sha512-0gSFWUPNXNopqtIPQvlD5WgXYI5GY2kP2cCvoT8kczjbfcfuIljTbcWrulD1CIPIX2gt1wghbDy08yE1p+/r3w==",
L225:       "dev": true,
L226:       "license": "MIT",
L227:       "dependencies": {
L228:         "@babel/traverse": "^7.27.1",
L229:         "@babel/types": "^7.27.1"
L230:       },
L231:       "engines": {
L232:         "node": ">=6.9.0"
L233:       }
L234:     },
L235:     "node_modules/@babel/helper-module-transforms": {
L236:       "version": "7.28.3",
L237:       "resolved": "https://registry.npmjs.org/@babel/helper-module-transforms/-/helper-module-transforms-7.28.3.tgz",
L238:       "integrity": "sha512-gytXUbs8k2sXS9PnQptz5o0QnpLL51SwASIORY6XaBKF88nsOT0Zw9szLqlSGQDP/4TljBAD5y98p2U1fqkdsw==",
L239:       "dev": true,
L240:       "license": "MIT",
L241:       "dependencies": {
L242:         "@babel/helper-module-imports": "^7.27.1",
L243:         "@babel/helper-validator-identifier": "^7.27.1",
L244:         "@babel/traverse": "^7.28.3"
L245:       },
L246:       "engines": {
L247:         "node": ">=6.9.0"
L248:       },
L249:       "peerDependencies": {
L250:         "@babel/core": "^7.0.0"
L251:       }
L252:     },
L253:     "node_modules/@babel/helper-plugin-utils": {
L254:       "version": "7.27.1",
L255:       "resolved": "https://registry.npmjs.org/@babel/helper-plugin-utils/-/helper-plugin-utils-7.27.1.tgz",
L256:       "integrity": "sha512-1gn1Up5YXka3YYAHGKpbideQ5Yjf1tDa9qYcgysz+cNCXukyLl6DjPXhD3VRwSb8c0J9tA4b2+rHEZtc6R0tlw==",
L257:       "dev": true,
L258:       "license": "MIT",
L259:       "engines": {
L260:         "node": ">=6.9.0"
L261:       }
L262:     },
L263:     "node_modules/@babel/helper-string-parser": {
L264:       "version": "7.27.1",
L265:       "resolved": "https://registry.npmjs.org/@babel/helper-string-parser/-/helper-string-parser-7.27.1.tgz",
L266:       "integrity": "sha512-qMlSxKbpRlAridDExk92nSobyDdpPijUq2DW6oDnUqd0iOGxmQjyqhMIihI9+zv4LPyZdRje2cavWPbCbWm3eA==",
L267:       "dev": true,
L268:       "license": "MIT",
L269:       "engines": {
L270:         "node": ">=6.9.0"
L271:       }
L272:     },
L273:     "node_modules/@babel/helper-validator-identifier": {
L274:       "version": "7.27.1",
L275:       "resolved": "https://registry.npmjs.org/@babel/helper-validator-identifier/-/helper-validator-identifier-7.27.1.tgz",
L276:       "integrity": "sha512-D2hP9eA+Sqx1kBZgzxZh0y1trbuU+JoDkiEwqhQ36nodYqJwyEIhPSdMNd7lOm/4io72luTPWH20Yda0xOuUow==",
L277:       "dev": true,
L278:       "license": "MIT",
L279:       "engines": {
L280:         "node": ">=6.9.0"
L281:       }
L282:     },
L283:     "node_modules/@babel/helper-validator-option": {
L284:       "version": "7.27.1",
L285:       "resolved": "https://registry.npmjs.org/@babel/helper-validator-option/-/helper-validator-option-7.27.1.tgz",
L286:       "integrity": "sha512-YvjJow9FxbhFFKDSuFnVCe2WxXk1zWc22fFePVNEaWJEu8IrZVlda6N0uHwzZrUM1il7NC9Mlp4MaJYbYd9JSg==",
L287:       "dev": true,
L288:       "license": "MIT",
L289:       "engines": {
L290:         "node": ">=6.9.0"
L291:       }
L292:     },
L293:     "node_modules/@babel/helpers": {
L294:       "version": "7.28.4",
L295:       "resolved": "https://registry.npmjs.org/@babel/helpers/-/helpers-7.28.4.tgz",
L296:       "integrity": "sha512-HFN59MmQXGHVyYadKLVumYsA9dBFun/ldYxipEjzA4196jpLZd8UjEEBLkbEkvfYreDqJhZxYAWFPtrfhNpj4w==",
L297:       "dev": true,
L298:       "license": "MIT",
L299:       "dependencies": {
L300:         "@babel/template": "^7.27.2",
L301:         "@babel/types": "^7.28.4"
L302:       },
L303:       "engines": {
L304:         "node": ">=6.9.0"
L305:       }
L306:     },
L307:     "node_modules/@babel/parser": {
L308:       "version": "7.28.4",
L309:       "resolved": "https://registry.npmjs.org/@babel/parser/-/parser-7.28.4.tgz",
L310:       "integrity": "sha512-yZbBqeM6TkpP9du/I2pUZnJsRMGGvOuIrhjzC1AwHwW+6he4mni6Bp/m8ijn0iOuZuPI2BfkCoSRunpyjnrQKg==",
L311:       "dev": true,
L312:       "license": "MIT",
L313:       "dependencies": {
L314:         "@babel/types": "^7.28.4"
L315:       },
L316:       "bin": {
L317:         "parser": "bin/babel-parser.js"
L318:       },
L319:       "engines": {
L320:         "node": ">=6.0.0"
L321:       }
L322:     },
L323:     "node_modules/@babel/plugin-transform-react-jsx-self": {
L324:       "version": "7.27.1",
L325:       "resolved": "https://registry.npmjs.org/@babel/plugin-transform-react-jsx-self/-/plugin-transform-react-jsx-self-7.27.1.tgz",
L326:       "integrity": "sha512-6UzkCs+ejGdZ5mFFC/OCUrv028ab2fp1znZmCZjAOBKiBK2jXD1O+BPSfX8X2qjJ75fZBMSnQn3Rq2mrBJK2mw==",
L327:       "dev": true,
L328:       "license": "MIT",
L329:       "dependencies": {
L330:         "@babel/helper-plugin-utils": "^7.27.1"
L331:       },
L332:       "engines": {
L333:         "node": ">=6.9.0"
L334:       },
L335:       "peerDependencies": {
L336:         "@babel/core": "^7.0.0-0"
L337:       }
L338:     },
L339:     "node_modules/@babel/plugin-transform-react-jsx-source": {
L340:       "version": "7.27.1",
L341:       "resolved": "https://registry.npmjs.org/@babel/plugin-transform-react-jsx-source/-/plugin-transform-react-jsx-source-7.27.1.tgz",
L342:       "integrity": "sha512-zbwoTsBruTeKB9hSq73ha66iFeJHuaFkUbwvqElnygoNbj/jHRsSeokowZFN3CZ64IvEqcmmkVe89OPXc7ldAw==",
L343:       "dev": true,
L344:       "license": "MIT",
L345:       "dependencies": {
L346:         "@babel/helper-plugin-utils": "^7.27.1"
L347:       },
L348:       "engines": {
L349:         "node": ">=6.9.0"
L350:       },
L351:       "peerDependencies": {
L352:         "@babel/core": "^7.0.0-0"
L353:       }
L354:     },
L355:     "node_modules/@babel/runtime": {
L356:       "version": "7.27.0",
L357:       "resolved": "https://registry.npmjs.org/@babel/runtime/-/runtime-7.27.0.tgz",
L358:       "integrity": "sha512-VtPOkrdPHZsKc/clNqyi9WUA8TINkZ4cGk63UUE3u4pmB2k+ZMQRDuIOagv8UVd6j7k0T3+RRIb7beKTebNbcw==",
L359:       "dependencies": {
L360:         "regenerator-runtime": "^0.14.0"
L361:       },
L362:       "engines": {
L363:         "node": ">=6.9.0"
L364:       }
L365:     },
L366:     "node_modules/@babel/template": {
L367:       "version": "7.27.2",
L368:       "resolved": "https://registry.npmjs.org/@babel/template/-/template-7.27.2.tgz",
L369:       "integrity": "sha512-LPDZ85aEJyYSd18/DkjNh4/y1ntkE5KwUHWTiqgRxruuZL2F1yuHligVHLvcHY2vMHXttKFpJn6LwfI7cw7ODw==",
L370:       "dev": true,
L371:       "license": "MIT",
L372:       "dependencies": {
L373:         "@babel/code-frame": "^7.27.1",
L374:         "@babel/parser": "^7.27.2",
L375:         "@babel/types": "^7.27.1"
L376:       },
L377:       "engines": {
L378:         "node": ">=6.9.0"
L379:       }
L380:     },
L381:     "node_modules/@babel/traverse": {
L382:       "version": "7.28.4",
L383:       "resolved": "https://registry.npmjs.org/@babel/traverse/-/traverse-7.28.4.tgz",
L384:       "integrity": "sha512-YEzuboP2qvQavAcjgQNVgsvHIDv6ZpwXvcvjmyySP2DIMuByS/6ioU5G9pYrWHM6T2YDfc7xga9iNzYOs12CFQ==",
L385:       "dev": true,
L386:       "license": "MIT",
L387:       "dependencies": {
L388:         "@babel/code-frame": "^7.27.1",
L389:         "@babel/generator": "^7.28.3",
L390:         "@babel/helper-globals": "^7.28.0",
L391:         "@babel/parser": "^7.28.4",
L392:         "@babel/template": "^7.27.2",
L393:         "@babel/types": "^7.28.4",
L394:         "debug": "^4.3.1"
L395:       },
L396:       "engines": {
L397:         "node": ">=6.9.0"
L398:       }
L399:     },
L400:     "node_modules/@babel/types": {
L401:       "version": "7.28.4",
L402:       "resolved": "https://registry.npmjs.org/@babel/types/-/types-7.28.4.tgz",
L403:       "integrity": "sha512-bkFqkLhh3pMBUQQkpVgWDWq/lqzc2678eUyDlTBhRqhCHFguYYGM0Efga7tYk4TogG/3x0EEl66/OQ+WGbWB/Q==",
L404:       "dev": true,
L405:       "license": "MIT",
L406:       "dependencies": {
L407:         "@babel/helper-string-parser": "^7.27.1",
L408:         "@babel/helper-validator-identifier": "^7.27.1"
L409:       },
L410:       "engines": {
L411:         "node": ">=6.9.0"
L412:       }
L413:     },
L414:     "node_modules/@drizzle-team/brocli": {
L415:       "version": "0.10.2",
L416:       "resolved": "https://registry.npmjs.org/@drizzle-team/brocli/-/brocli-0.10.2.tgz",
L417:       "integrity": "sha512-z33Il7l5dKjUgGULTqBsQBQwckHh5AbIuxhdsIxDDiZAzBOrZO6q9ogcWC65kU382AfynTfgNumVcNIjuIua6w==",
L418:       "dev": true,
L419:       "license": "Apache-2.0"
L420:     },
L421:     "node_modules/@esbuild/aix-ppc64": {
L422:       "version": "0.25.12",
L423:       "resolved": "https://registry.npmjs.org/@esbuild/aix-ppc64/-/aix-ppc64-0.25.12.tgz",
L424:       "integrity": "sha512-Hhmwd6CInZ3dwpuGTF8fJG6yoWmsToE+vYgD4nytZVxcu1ulHpUQRAB1UJ8+N1Am3Mz4+xOByoQoSZf4D+CpkA==",
L425:       "cpu": [
L426:         "ppc64"
L427:       ],
L428:       "dev": true,
L429:       "license": "MIT",
L430:       "optional": true,
L431:       "os": [
L432:         "aix"
L433:       ],
L434:       "engines": {
L435:         "node": ">=18"
L436:       }
L437:     },
L438:     "node_modules/@esbuild/android-arm": {
L439:       "version": "0.25.12",
L440:       "resolved": "https://registry.npmjs.org/@esbuild/android-arm/-/android-arm-0.25.12.tgz",
L441:       "integrity": "sha512-VJ+sKvNA/GE7Ccacc9Cha7bpS8nyzVv0jdVgwNDaR4gDMC/2TTRc33Ip8qrNYUcpkOHUT5OZ0bUcNNVZQ9RLlg==",
L442:       "cpu": [
L443:         "arm"
L444:       ],
L445:       "dev": true,
L446:       "license": "MIT",
L447:       "optional": true,
L448:       "os": [
L449:         "android"
L450:       ],
L451:       "engines": {
L452:         "node": ">=18"
L453:       }
L454:     },
L455:     "node_modules/@esbuild/android-arm64": {
L456:       "version": "0.25.12",
L457:       "resolved": "https://registry.npmjs.org/@esbuild/android-arm64/-/android-arm64-0.25.12.tgz",
L458:       "integrity": "sha512-6AAmLG7zwD1Z159jCKPvAxZd4y/VTO0VkprYy+3N2FtJ8+BQWFXU+OxARIwA46c5tdD9SsKGZ/1ocqBS/gAKHg==",
L459:       "cpu": [
L460:         "arm64"
L461:       ],
L462:       "dev": true,
L463:       "license": "MIT",
L464:       "optional": true,
L465:       "os": [
L466:         "android"
L467:       ],
L468:       "engines": {
L469:         "node": ">=18"
L470:       }
L471:     },
L472:     "node_modules/@esbuild/android-x64": {
L473:       "version": "0.25.12",
L474:       "resolved": "https://registry.npmjs.org/@esbuild/android-x64/-/android-x64-0.25.12.tgz",
L475:       "integrity": "sha512-5jbb+2hhDHx5phYR2By8GTWEzn6I9UqR11Kwf22iKbNpYrsmRB18aX/9ivc5cabcUiAT/wM+YIZ6SG9QO6a8kg==",
L476:       "cpu": [
L477:         "x64"
L478:       ],
L479:       "dev": true,
L480:       "license": "MIT",
L481:       "optional": true,
L482:       "os": [
L483:         "android"
L484:       ],
L485:       "engines": {
L486:         "node": ">=18"
L487:       }
L488:     },
L489:     "node_modules/@esbuild/darwin-arm64": {
L490:       "version": "0.25.12",
L491:       "resolved": "https://registry.npmjs.org/@esbuild/darwin-arm64/-/darwin-arm64-0.25.12.tgz",
L492:       "integrity": "sha512-N3zl+lxHCifgIlcMUP5016ESkeQjLj/959RxxNYIthIg+CQHInujFuXeWbWMgnTo4cp5XVHqFPmpyu9J65C1Yg==",
L493:       "cpu": [
L494:         "arm64"
L495:       ],
L496:       "dev": true,
L497:       "license": "MIT",
L498:       "optional": true,
L499:       "os": [
L500:         "darwin"

--- FILE: main.py ---
L1: def main():
L2:     print("Hello from repl-nix-workspace!")
L3: 
L4: 
L5: if __name__ == "__main__":
L6:     main()

--- FILE: script/build.ts ---
L1: import { build as esbuild } from "esbuild";
L2: import { build as viteBuild } from "vite";
L3: import { rm, readFile } from "fs/promises";
L4: 
L5: // server deps to bundle to reduce openat(2) syscalls
L6: // which helps cold start times
L7: const allowlist = [
L8:   "@google/generative-ai",
L9:   "axios",
L10:   "connect-pg-simple",
L11:   "cors",
L12:   "date-fns",
L13:   "drizzle-orm",
L14:   "drizzle-zod",
L15:   "express",
L16:   "express-rate-limit",
L17:   "express-session",
L18:   "jsonwebtoken",
L19:   "memorystore",
L20:   "multer",
L21:   "nanoid",
L22:   "nodemailer",
L23:   "openai",
L24:   "passport",
L25:   "passport-local",
L26:   "pg",
L27:   "stripe",
L28:   "uuid",
L29:   "ws",
L30:   "xlsx",
L31:   "zod",
L32:   "zod-validation-error",
L33: ];
L34: 
L35: async function buildAll() {
L36:   await rm("dist", { recursive: true, force: true });
L37: 
L38:   console.log("building client...");
L39:   await viteBuild();
L40: 
L41:   console.log("building server...");
L42:   const pkg = JSON.parse(await readFile("package.json", "utf-8"));
L43:   const allDeps = [
L44:     ...Object.keys(pkg.dependencies || {}),
L45:     ...Object.keys(pkg.devDependencies || {}),
L46:   ];
L47:   const externals = allDeps.filter((dep) => !allowlist.includes(dep));
L48: 
L49:   await esbuild({
L50:     entryPoints: ["server/index.ts"],
L51:     platform: "node",
L52:     bundle: true,
L53:     format: "cjs",
L54:     outfile: "dist/index.cjs",
L55:     define: {
L56:       "process.env.NODE_ENV": '"production"',
L57:     },
L58:     minify: true,
L59:     external: externals,
L60:     logLevel: "info",
L61:   });
L62: }
L63: 
L64: buildAll().catch((err) => {
L65:   console.error(err);
L66:   process.exit(1);
L67: });

--- FILE: server/index.ts ---
L1: import express, { type Request, Response, NextFunction } from "express";
L2: import { registerRoutes } from "./routes";
L3: import { serveStatic } from "./static";
L4: import { createServer } from "http";
L5: 
L6: const app = express();
L7: const httpServer = createServer(app);
L8: 
L9: declare module "http" {
L10:   interface IncomingMessage {
L11:     rawBody: unknown;
L12:   }
L13: }
L14: 
L15: app.use(
L16:   express.json({
L17:     verify: (req, _res, buf) => {
L18:       req.rawBody = buf;
L19:     },
L20:   }),
L21: );
L22: 
L23: app.use(express.urlencoded({ extended: false }));
L24: 
L25: export function log(message: string, source = "express") {
L26:   const formattedTime = new Date().toLocaleTimeString("en-US", {
L27:     hour: "numeric",
L28:     minute: "2-digit",
L29:     second: "2-digit",
L30:     hour12: true,
L31:   });
L32: 
L33:   console.log(`${formattedTime} [${source}] ${message}`);
L34: }
L35: 
L36: app.use((req, res, next) => {
L37:   const start = Date.now();
L38:   const path = req.path;
L39:   let capturedJsonResponse: Record<string, any> | undefined = undefined;
L40: 
L41:   const originalResJson = res.json;
L42:   res.json = function (bodyJson, ...args) {
L43:     capturedJsonResponse = bodyJson;
L44:     return originalResJson.apply(res, [bodyJson, ...args]);
L45:   };
L46: 
L47:   res.on("finish", () => {
L48:     const duration = Date.now() - start;
L49:     if (path.startsWith("/api")) {
L50:       let logLine = `${req.method} ${path} ${res.statusCode} in ${duration}ms`;
L51:       if (capturedJsonResponse) {
L52:         logLine += ` :: ${JSON.stringify(capturedJsonResponse)}`;
L53:       }
L54: 
L55:       log(logLine);
L56:     }
L57:   });
L58: 
L59:   next();
L60: });
L61: 
L62: (async () => {
L63:   await registerRoutes(httpServer, app);
L64: 
L65:   app.use((err: any, _req: Request, res: Response, next: NextFunction) => {
L66:     const status = err.status || err.statusCode || 500;
L67:     const message = err.message || "Internal Server Error";
L68: 
L69:     console.error("Internal Server Error:", err);
L70: 
L71:     if (res.headersSent) {
L72:       return next(err);
L73:     }
L74: 
L75:     return res.status(status).json({ message });
L76:   });
L77: 
L78:   // importantly only setup vite in development and after
L79:   // setting up all the other routes so the catch-all route
L80:   // doesn't interfere with the other routes
L81:   if (process.env.NODE_ENV === "production") {
L82:     serveStatic(app);
L83:   } else {
L84:     const { setupVite } = await import("./vite");
L85:     await setupVite(httpServer, app);
L86:   }
L87: 
L88:   // ALWAYS serve the app on the port specified in the environment variable PORT
L89:   // Other ports are firewalled. Default to 5000 if not specified.
L90:   // this serves both the API and the client.
L91:   // It is the only port that is not firewalled.
L92:   const port = parseInt(process.env.PORT || "5000", 10);
L93:   httpServer.listen(
L94:     {
L95:       port,
L96:       host: "0.0.0.0",
L97:       reusePort: true,
L98:     },
L99:     () => {
L100:       log(`serving on port ${port}`);
L101:     },
L102:   );
L103: })();

--- FILE: server/static.ts ---
L1: import express, { type Express } from "express";
L2: import fs from "fs";
L3: import path from "path";
L4: 
L5: export function serveStatic(app: Express) {
L6:   const distPath = path.resolve(__dirname, "public");
L7:   if (!fs.existsSync(distPath)) {
L8:     throw new Error(
L9:       `Could not find the build directory: ${distPath}, make sure to build the client first`,
L10:     );
L11:   }
L12: 
L13:   app.use(express.static(distPath));
L14: 
L15:   // fall through to index.html if the file doesn't exist
L16:   app.use("/{*path}", (_req, res) => {
L17:     res.sendFile(path.resolve(distPath, "index.html"));
L18:   });
L19: }

--- FILE: server/vite.ts ---
L1: import { type Express } from "express";
L2: import { createServer as createViteServer, createLogger } from "vite";
L3: import { type Server } from "http";
L4: import viteConfig from "../vite.config";
L5: import fs from "fs";
L6: import path from "path";
L7: import { nanoid } from "nanoid";
L8: 
L9: const viteLogger = createLogger();
L10: 
L11: export async function setupVite(server: Server, app: Express) {
L12:   const serverOptions = {
L13:     middlewareMode: true,
L14:     hmr: { server, path: "/vite-hmr" },
L15:     allowedHosts: true as const,
L16:   };
L17: 
L18:   const vite = await createViteServer({
L19:     ...viteConfig,
L20:     configFile: false,
L21:     customLogger: {
L22:       ...viteLogger,
L23:       error: (msg, options) => {
L24:         viteLogger.error(msg, options);
L25:         process.exit(1);
L26:       },
L27:     },
L28:     server: serverOptions,
L29:     appType: "custom",
L30:   });
L31: 
L32:   app.use(vite.middlewares);
L33: 
L34:   app.use("/{*path}", async (req, res, next) => {
L35:     const url = req.originalUrl;
L36: 
L37:     try {
L38:       const clientTemplate = path.resolve(
L39:         import.meta.dirname,
L40:         "..",
L41:         "client",
L42:         "index.html",
L43:       );
L44: 
L45:       // always reload the index.html file from disk incase it changes
L46:       let template = await fs.promises.readFile(clientTemplate, "utf-8");
L47:       template = template.replace(
L48:         `src="/src/main.tsx"`,
L49:         `src="/src/main.tsx?v=${nanoid()}"`,
L50:       );
L51:       const page = await vite.transformIndexHtml(url, template);
L52:       res.status(200).set({ "Content-Type": "text/html" }).end(page);
L53:     } catch (e) {
L54:       vite.ssrFixStacktrace(e as Error);
L55:       next(e);
L56:     }
L57:   });
L58: }

--- FILE: server/db.ts ---
L1: import { drizzle } from "drizzle-orm/node-postgres";
L2: import pg from "pg";
L3: import * as schema from "@shared/schema";
L4: 
L5: const { Pool } = pg;
L6: 
L7: if (!process.env.DATABASE_URL) {
L8:   throw new Error(
L9:     "DATABASE_URL must be set. Did you forget to provision a database?",
L10:   );
L11: }
L12: 
L13: export const pool = new Pool({ connectionString: process.env.DATABASE_URL });
L14: export const db = drizzle(pool, { schema });

--- FILE: server/__init__.py ---


--- FILE: server/storage.ts ---
L1: import { db } from "./db";
L2: import { pool } from "./db";
L3: import {
L4:   projects, analyses, ciRuns, ciJobs,
L5:   type InsertProject, type InsertAnalysis, type Project, type Analysis,
L6:   type CiRun, type InsertCiRun, type CiJob,
L7: } from "@shared/schema";
L8: import { eq, desc, and, or, lt, asc, sql } from "drizzle-orm";
L9: 
L10: export interface IStorage {
L11:   createProject(project: InsertProject, mode?: string): Promise<Project>;
L12:   getProjects(): Promise<Project[]>;
L13:   getProject(id: number): Promise<Project | undefined>;
L14:   createAnalysis(analysis: InsertAnalysis): Promise<Analysis>;
L15:   getAnalysisByProjectId(projectId: number): Promise<Analysis | undefined>;
L16:   updateProjectStatus(id: number, status: string): Promise<Project>;
L17:   resetAnalyzerLogbook(): Promise<void>;
L18: 
L19:   createCiRun(run: InsertCiRun): Promise<CiRun>;
L20:   getCiRuns(owner: string, repo: string, limit?: number): Promise<CiRun[]>;
L21:   getCiRun(id: string): Promise<CiRun | undefined>;
L22:   updateCiRun(id: string, data: Partial<CiRun>): Promise<CiRun>;
L23:   findExistingCiRun(owner: string, repo: string, sha: string, withinHours?: number): Promise<CiRun | undefined>;
L24:   createCiJob(runId: string): Promise<CiJob>;
L25:   leaseNextJob(): Promise<{ job: CiJob; run: CiRun } | null>;
L26:   completeJob(jobId: string, status: "DONE" | "DEAD", error?: string): Promise<void>;
L27:   getCiJobCounts(): Promise<Record<string, number>>;
L28:   getLastCompletedRun(): Promise<CiRun | undefined>;
L29: }
L30: 
L31: export class DatabaseStorage implements IStorage {
L32:   async createProject(insertProject: InsertProject, mode: string = "github"): Promise<Project> {
L33:     const [project] = await db.insert(projects).values({ ...insertProject, mode }).returning();
L34:     return project;
L35:   }
L36: 
L37:   async getProjects(): Promise<Project[]> {
L38:     return await db.select().from(projects).orderBy(desc(projects.createdAt));
L39:   }
L40: 
L41:   async getProject(id: number): Promise<Project | undefined> {
L42:     const [project] = await db.select().from(projects).where(eq(projects.id, id));
L43:     return project;
L44:   }
L45: 
L46:   async createAnalysis(insertAnalysis: InsertAnalysis): Promise<Analysis> {
L47:     const [analysis] = await db.insert(analyses).values(insertAnalysis).returning();
L48:     return analysis;
L49:   }
L50: 
L51:   async getAnalysisByProjectId(projectId: number): Promise<Analysis | undefined> {
L52:     const [analysis] = await db.select().from(analyses).where(eq(analyses.projectId, projectId)).orderBy(desc(analyses.createdAt)).limit(1);
L53:     return analysis;
L54:   }
L55: 
L56:   async updateProjectStatus(id: number, status: string): Promise<Project> {
L57:     const [project] = await db.update(projects).set({ status }).where(eq(projects.id, id)).returning();
L58:     return project;
L59:   }
L60: 
L61:   async resetAnalyzerLogbook(): Promise<void> {
L62:     await db.delete(analyses);
L63:     await db.delete(projects);
L64:   }
L65: 
L66:   async createCiRun(run: InsertCiRun): Promise<CiRun> {
L67:     const [created] = await db.insert(ciRuns).values(run).returning();
L68:     return created;
L69:   }
L70: 
L71:   async getCiRuns(owner: string, repo: string, limit: number = 50): Promise<CiRun[]> {
L72:     return await db.select().from(ciRuns)
L73:       .where(and(eq(ciRuns.repoOwner, owner), eq(ciRuns.repoName, repo)))
L74:       .orderBy(desc(ciRuns.createdAt))
L75:       .limit(limit);
L76:   }
L77: 
L78:   async getCiRun(id: string): Promise<CiRun | undefined> {
L79:     const [run] = await db.select().from(ciRuns).where(eq(ciRuns.id, id));
L80:     return run;
L81:   }
L82: 
L83:   async updateCiRun(id: string, data: Partial<CiRun>): Promise<CiRun> {
L84:     const [updated] = await db.update(ciRuns).set(data).where(eq(ciRuns.id, id)).returning();
L85:     return updated;
L86:   }
L87: 
L88:   async findExistingCiRun(owner: string, repo: string, sha: string, withinHours: number = 6): Promise<CiRun | undefined> {
L89:     const cutoff = new Date(Date.now() - withinHours * 60 * 60 * 1000);
L90:     const results = await db.select().from(ciRuns)
L91:       .where(and(
L92:         eq(ciRuns.repoOwner, owner),
L93:         eq(ciRuns.repoName, repo),
L94:         eq(ciRuns.commitSha, sha),
L95:         sql`${ciRuns.createdAt} > ${cutoff}`,
L96:       ))
L97:       .orderBy(desc(ciRuns.createdAt))
L98:       .limit(1);
L99:     return results[0];
L100:   }
L101: 
L102:   async createCiJob(runId: string): Promise<CiJob> {
L103:     const [job] = await db.insert(ciJobs).values({ runId, status: "READY" }).returning();
L104:     return job;
L105:   }
L106: 
L107:   async leaseNextJob(): Promise<{ job: CiJob; run: CiRun } | null> {
L108:     const client = await pool.connect();
L109:     try {
L110:       await client.query("BEGIN");
L111:       const now = new Date();
L112:       const { rows } = await client.query(
L113:         `SELECT * FROM ci_jobs
L114:          WHERE status = 'READY' OR (status = 'LEASED' AND leased_until < $1)
L115:          ORDER BY created_at ASC
L116:          LIMIT 1
L117:          FOR UPDATE SKIP LOCKED`,
L118:         [now]
L119:       );
L120:       if (rows.length === 0) {
L121:         await client.query("ROLLBACK");
L122:         return null;
L123:       }
L124:       const row = rows[0];
L125:       if (row.attempts >= 3) {
L126:         await client.query(
L127:           `UPDATE ci_jobs SET status = 'DEAD', last_error = 'max_attempts_exceeded' WHERE id = $1`,
L128:           [row.id]
L129:         );
L130:         await client.query(
L131:           `UPDATE ci_runs SET status = 'FAILED', finished_at = $1, error = 'max_attempts_exceeded' WHERE id = $2`,
L132:           [now, row.run_id]
L133:         );
L134:         await client.query("COMMIT");
L135:         return null;
L136:       }
L137:       const leaseUntil = new Date(Date.now() + 5 * 60 * 1000);
L138:       await client.query(
L139:         `UPDATE ci_jobs SET status = 'LEASED', attempts = attempts + 1, leased_until = $1 WHERE id = $2`,
L140:         [leaseUntil, row.id]
L141:       );
L142:       await client.query(
L143:         `UPDATE ci_runs SET status = 'RUNNING', started_at = COALESCE(started_at, $1) WHERE id = $2`,
L144:         [now, row.run_id]
L145:       );
L146:       await client.query("COMMIT");
L147: 
L148:       const job = await this.getCiJobById(row.id);
L149:       const run = await this.getCiRun(row.run_id);
L150:       if (!job || !run) return null;
L151:       return { job, run };
L152:     } catch (err) {
L153:       await client.query("ROLLBACK");
L154:       throw err;
L155:     } finally {
L156:       client.release();
L157:     }
L158:   }
L159: 
L160:   private async getCiJobById(id: string): Promise<CiJob | undefined> {
L161:     const [job] = await db.select().from(ciJobs).where(eq(ciJobs.id, id));
L162:     return job;
L163:   }
L164: 
L165:   async completeJob(jobId: string, status: "DONE" | "DEAD", error?: string): Promise<void> {
L166:     await db.update(ciJobs).set({ status, lastError: error || null }).where(eq(ciJobs.id, jobId));
L167:   }
L168: 
L169:   async getCiJobCounts(): Promise<Record<string, number>> {
L170:     const result = await db.select({
L171:       status: ciJobs.status,
L172:       count: sql<number>`count(*)::int`,
L173:     }).from(ciJobs).groupBy(ciJobs.status);
L174:     const counts: Record<string, number> = {};
L175:     for (const r of result) {
L176:       counts[r.status] = r.count;
L177:     }
L178:     return counts;
L179:   }
L180: 
L181:   async getLastCompletedRun(): Promise<CiRun | undefined> {
L182:     const results = await db.select().from(ciRuns)
L183:       .where(or(eq(ciRuns.status, "SUCCEEDED"), eq(ciRuns.status, "FAILED")))
L184:       .orderBy(desc(ciRuns.finishedAt))
L185:       .limit(1);
L186:     return results[0];
L187:   }
L188: }
L189: 
L190: export const storage = new DatabaseStorage();

--- FILE: server/routes.ts ---
L1: import type { Express, Request, Response } from "express";
L2: import { createServer, type Server } from "http";
L3: import { storage } from "./storage";
L4: import { api } from "@shared/routes";
L5: import { z } from "zod";
L6: import { spawn } from "child_process";
L7: import path from "path";
L8: import fs from "fs/promises";
L9: import { existsSync, readFileSync, appendFileSync, mkdirSync } from "fs";
L10: import crypto from "crypto";
L11: import { processOneJob, startWorkerLoop } from "./ci-worker";
L12: 
L13: const LOG_DIR = path.resolve(process.cwd(), "out", "_log");
L14: const LOG_FILE = path.join(LOG_DIR, "analyzer.ndjson");
L15: 
L16: function logEvent(projectId: number, event: string, detail?: Record<string, unknown>) {
L17:   mkdirSync(LOG_DIR, { recursive: true });
L18:   const entry = {
L19:     ts: new Date().toISOString(),
L20:     projectId,
L21:     event,
L22:     ...detail,
L23:   };
L24:   appendFileSync(LOG_FILE, JSON.stringify(entry) + "\n");
L25: }
L26: 
L27: function logAdminEvent(event: string, detail?: Record<string, unknown>) {
L28:   logEvent(0, event, detail);
L29: }
L30: 
L31: function requireDevAdmin(req: any, res: any): boolean {
L32:   if (process.env.NODE_ENV === "production") {
L33:     res.status(403).json({ error: "Forbidden" });
L34:     return false;
L35:   }
L36:   const required = process.env.ADMIN_KEY;
L37:   if (required && required.length > 0) {
L38:     const provided = String(req.headers["x-admin-key"] || "");
L39:     if (provided !== required) {
L40:       res.status(401).json({ error: "Unauthorized" });
L41:       return false;
L42:     }
L43:   } else {
L44:     logAdminEvent("admin_unguarded", {
L45:       path: req.path,
L46:       ip: req.ip,
L47:       ua: String(req.headers["user-agent"] || ""),
L48:     });
L49:   }
L50:   return true;
L51: }
L52: 
L53: export async function registerRoutes(
L54:   httpServer: Server,
L55:   app: Express
L56: ): Promise<Server> {
L57:   app.get("/health", async (_req, res) => {
L58:     const dbOk = await storage.getProjects().then(() => true).catch(() => false);
L59:     res.json({ ok: true, db: dbOk, uptime: process.uptime() });
L60:   });
L61: 
L62:   app.get(api.projects.list.path, async (_req, res) => {
L63:     const projects = await storage.getProjects();
L64:     res.json(projects);
L65:   });
L66: 
L67:   app.post(api.projects.create.path, async (req, res) => {
L68:     try {
L69:       const input = api.projects.create.input.parse(req.body);
L70:       const { mode, ...projectData } = input;
L71:       const project = await storage.createProject(projectData, mode || "github");
L72:       res.status(201).json(project);
L73:     } catch (err) {
L74:       if (err instanceof z.ZodError) {
L75:         res.status(400).json({
L76:           message: err.errors[0].message,
L77:           field: err.errors[0].path.join('.'),
L78:         });
L79:         return;
L80:       }
L81:       res.status(500).json({ message: "Internal server error" });
L82:     }
L83:   });
L84: 
L85:   app.get(api.projects.get.path, async (req, res) => {
L86:     const project = await storage.getProject(Number(req.params.id));
L87:     if (!project) {
L88:       return res.status(404).json({ message: 'Project not found' });
L89:     }
L90:     res.json(project);
L91:   });
L92: 
L93:   app.get(api.projects.getAnalysis.path, async (req, res) => {
L94:     const analysis = await storage.getAnalysisByProjectId(Number(req.params.id));
L95:     if (!analysis) {
L96:       return res.status(404).json({ message: 'Analysis not found' });
L97:     }
L98:     res.json(analysis);
L99:   });
L100: 
L101:   app.post(api.projects.analyze.path, async (req, res) => {
L102:     const projectId = Number(req.params.id);
L103:     const project = await storage.getProject(projectId);
L104: 
L105:     if (!project) {
L106:       return res.status(404).json({ message: "Project not found" });
L107:     }
L108: 
L109:     runAnalysis(project.id, project.url, project.mode || "github");
L110: 
L111:     res.status(202).json({ message: "Analysis started" });
L112:   });
L113: 
L114:   app.post(api.projects.analyzeReplit.path, async (req, res) => {
L115:     try {
L116:       const workspaceRoot = process.cwd();
L117:       const folderName = path.basename(workspaceRoot);
L118: 
L119:       const project = await storage.createProject(
L120:         { url: workspaceRoot, name: `Replit: ${folderName}` },
L121:         "replit"
L122:       );
L123: 
L124:       runAnalysis(project.id, workspaceRoot, "replit");
L125: 
L126:       res.status(201).json(project);
L127:     } catch (err) {
L128:       console.error("Error starting Replit analysis:", err);
L129:       res.status(500).json({ message: "Failed to start Replit analysis" });
L130:     }
L131:   });
L132: 
L133:   app.get("/api/dossiers/lantern", (_req, res) => {
L134:     const p = path.join(process.cwd(), "docs/dossiers/lantern_program_totality_dossier.md");
L135:     if (!existsSync(p)) return res.status(404).json({ error: "Not found" });
L136:     res.type("text/markdown").send(readFileSync(p, "utf8"));
L137:   });
L138: 
L139:   app.get("/api/admin/analyzer-log", async (req, res) => {
L140:     if (!requireDevAdmin(req, res)) return;
L141:     try {
L142:       if (!existsSync(LOG_FILE)) return res.json([]);
L143:       const raw = await fs.readFile(LOG_FILE, "utf-8");
L144:       const lines = raw.split("\n").filter(Boolean);
L145:       const parsed = lines.map((l) => {
L146:         try { return JSON.parse(l); } catch { return { parse_error: true, line: l }; }
L147:       });
L148:       res.json(parsed);
L149:     } catch (err) {
L150:       res.status(500).json({ error: "failed_to_read_log" });
L151:     }
L152:   });
L153: 
L154:   app.post("/api/admin/analyzer-log/clear", async (req, res) => {
L155:     if (!requireDevAdmin(req, res)) return;
L156:     try {
L157:       await fs.mkdir(LOG_DIR, { recursive: true });
L158:       await fs.rm(LOG_FILE, { force: true });
L159:       await fs.writeFile(LOG_FILE, "", "utf8");
L160:       logAdminEvent("log_cleared", {
L161:         ip: req.ip,
L162:         ua: String(req.headers["user-agent"] || ""),
L163:       });
L164:       return res.json({ ok: true });
L165:     } catch (err) {
L166:       console.error("Failed to clear analyzer log:", err);
L167:       return res.status(500).json({ ok: false });
L168:     }
L169:   });
L170: 
L171:   app.post("/api/admin/reset-analyzer", async (req, res) => {
L172:     if (!requireDevAdmin(req, res)) return;
L173:     try {
L174:       await storage.resetAnalyzerLogbook();
L175:       await fs.rm(path.resolve(process.cwd(), "out"), { recursive: true, force: true });
L176:       await fs.mkdir(path.resolve(process.cwd(), "out"), { recursive: true });
L177:       logAdminEvent("reset_analyzer", {
L178:         ip: req.ip,
L179:         ua: String(req.headers["user-agent"] || ""),
L180:       });
L181:       console.log("[Admin] Analyzer logbook + DB + out/ reset");
L182:       res.json({ ok: true });
L183:     } catch (err) {
L184:       console.error("[Admin] Reset failed:", err);
L185:       res.status(500).json({ message: "Reset failed" });
L186:     }
L187:   });
L188: 
L189:   // ============== CI FEED ROUTES ==============
L190: 
L191:   const webhookRateLimiter = createRateLimiter(30, 60_000);
L192: 
L193:   app.post("/api/webhooks/github", async (req: Request, res: Response) => {
L194:     if (!webhookRateLimiter()) {
L195:       return res.status(429).json({ error: "rate_limited" });
L196:     }
L197: 
L198:     const secret = process.env.GITHUB_WEBHOOK_SECRET;
L199:     if (!secret) {
L200:       console.error("[Webhook] GITHUB_WEBHOOK_SECRET not set");
L201:       return res.status(500).json({ error: "webhook_not_configured" });
L202:     }
L203: 
L204:     const sigHeader = req.headers["x-hub-signature-256"] as string | undefined;
L205:     if (!sigHeader) {
L206:       return res.status(401).json({ error: "missing_signature" });
L207:     }
L208: 
L209:     const rawBody = JSON.stringify(req.body);
L210:     const expected = "sha256=" + crypto.createHmac("sha256", secret).update(rawBody).digest("hex");
L211:     const sigBuf = Buffer.from(sigHeader);
L212:     const expBuf = Buffer.from(expected);
L213:     if (sigBuf.length !== expBuf.length || !crypto.timingSafeEqual(sigBuf, expBuf)) {
L214:       return res.status(401).json({ error: "invalid_signature" });
L215:     }
L216: 
L217:     const event = req.headers["x-github-event"] as string;
L218:     const payload = req.body;
L219: 
L220:     if (event === "push") {
L221:       const owner = payload.repository?.owner?.login || payload.repository?.owner?.name;
L222:       const repo = payload.repository?.name;
L223:       const refFull = payload.ref || "";
L224:       const ref = refFull.replace("refs/heads/", "");
L225:       const sha = payload.after;
L226: 
L227:       if (!owner || !repo || !sha) {
L228:         return res.status(400).json({ error: "missing_fields" });
L229:       }
L230: 
L231:       const existing = await storage.findExistingCiRun(owner, repo, sha);
L232:       if (existing) {
L233:         console.log(`[Webhook] Deduplicated push for ${owner}/${repo}@${sha}`);
L234:         return res.json({ ok: true, run_id: existing.id, deduplicated: true });
L235:       }
L236: 
L237:       const run = await storage.createCiRun({ repoOwner: owner, repoName: repo, ref, commitSha: sha, eventType: "push", status: "QUEUED" });
L238:       await storage.createCiJob(run.id);
L239:       console.log(`[Webhook] Created run ${run.id} for push ${owner}/${repo}@${sha}`);
L240:       return res.json({ ok: true, run_id: run.id });
L241: 
L242:     } else if (event === "pull_request") {
L243:       const action = payload.action;
L244:       if (!["opened", "synchronize", "reopened"].includes(action)) {
L245:         return res.status(202).json({ ok: true, ignored: true });
L246:       }
L247: 
L248:       const owner = payload.repository?.owner?.login;
L249:       const repo = payload.repository?.name;
L250:       const ref = payload.pull_request?.head?.ref;
L251:       const sha = payload.pull_request?.head?.sha;
L252: 
L253:       if (!owner || !repo || !ref || !sha) {
L254:         return res.status(400).json({ error: "missing_fields" });
L255:       }
L256: 
L257:       const existing = await storage.findExistingCiRun(owner, repo, sha);
L258:       if (existing) {
L259:         return res.json({ ok: true, run_id: existing.id, deduplicated: true });
L260:       }
L261: 
L262:       const run = await storage.createCiRun({ repoOwner: owner, repoName: repo, ref, commitSha: sha, eventType: "pull_request", status: "QUEUED" });
L263:       await storage.createCiJob(run.id);
L264:       console.log(`[Webhook] Created run ${run.id} for PR ${owner}/${repo}@${sha}`);
L265:       return res.json({ ok: true, run_id: run.id });
L266: 
L267:     } else {
L268:       return res.status(202).json({ ok: true, ignored: true });
L269:     }
L270:   });
L271: 
L272:   app.get("/api/ci/runs", async (req: Request, res: Response) => {
L273:     const owner = String(req.query.owner || "");
L274:     const repo = String(req.query.repo || "");
L275:     const limit = Math.min(Number(req.query.limit) || 50, 200);
L276: 
L277:     if (!owner || !repo) {
L278:       return res.status(400).json({ error: "owner and repo query params required" });
L279:     }
L280: 
L281:     const runs = await storage.getCiRuns(owner, repo, limit);
L282:     res.json({ ok: true, runs });
L283:   });
L284: 
L285:   app.get("/api/ci/runs/:id", async (req: Request, res: Response) => {
L286:     const run = await storage.getCiRun(String(req.params.id));
L287:     if (!run) {
L288:       return res.status(404).json({ error: "run not found" });
L289:     }
L290:     res.json({ ok: true, run });
L291:   });
L292: 
L293:   app.post("/api/ci/enqueue", async (req: Request, res: Response) => {
L294:     const { owner, repo, ref, commit_sha, event_type } = req.body || {};
L295:     if (!owner || !repo || !ref || !commit_sha) {
L296:       return res.status(400).json({ error: "missing required fields: owner, repo, ref, commit_sha" });
L297:     }
L298: 
L299:     const existing = await storage.findExistingCiRun(owner, repo, commit_sha);
L300:     if (existing) {
L301:       return res.json({ ok: true, run_id: existing.id, deduplicated: true });
L302:     }
L303: 
L304:     const run = await storage.createCiRun({
L305:       repoOwner: owner,
L306:       repoName: repo,
L307:       ref,
L308:       commitSha: commit_sha,
L309:       eventType: event_type || "manual",
L310:       status: "QUEUED",
L311:     });
L312:     await storage.createCiJob(run.id);
L313:     console.log(`[CI] Manual enqueue: run=${run.id} ${owner}/${repo}@${commit_sha}`);
L314:     res.json({ ok: true, run_id: run.id });
L315:   });
L316: 
L317:   app.post("/api/ci/worker/tick", async (_req: Request, res: Response) => {
L318:     try {
L319:       const result = await processOneJob();
L320:       res.json({ ok: true, ...result });
L321:     } catch (err: any) {
L322:       res.status(500).json({ ok: false, error: String(err?.message || err) });
L323:     }
L324:   });
L325: 
L326:   app.get("/api/ci/health", async (_req: Request, res: Response) => {
L327:     try {
L328:       const jobCounts = await storage.getCiJobCounts();
L329:       const lastRun = await storage.getLastCompletedRun();
L330:       res.json({
L331:         ok: true,
L332:         jobs: jobCounts,
L333:         last_completed: lastRun ? {
L334:           id: lastRun.id,
L335:           status: lastRun.status,
L336:           finished_at: lastRun.finishedAt,
L337:           repo: `${lastRun.repoOwner}/${lastRun.repoName}`,
L338:         } : null,
L339:       });
L340:     } catch (err: any) {
L341:       res.status(500).json({ ok: false, error: String(err?.message || err) });
L342:     }
L343:   });
L344: 
L345:   startWorkerLoop();
L346: 
L347:   return httpServer;
L348: }
L349: 
L350: function createRateLimiter(maxRequests: number, windowMs: number) {
L351:   const timestamps: number[] = [];
L352:   return () => {
L353:     const now = Date.now();
L354:     while (timestamps.length > 0 && timestamps[0] < now - windowMs) {
L355:       timestamps.shift();
L356:     }
L357:     if (timestamps.length >= maxRequests) return false;
L358:     timestamps.push(now);
L359:     return true;
L360:   };
L361: }
L362: 
L363: async function runAnalysis(projectId: number, source: string, mode: string) {
L364:   const startTime = Date.now();
L365:   console.log(`[Analyzer ${projectId}] Starting: mode=${mode} source=${source}`);
L366:   logEvent(projectId, "start", { mode, source });
L367:   await storage.updateProjectStatus(projectId, "analyzing");
L368: 
L369:   const outputDir = path.resolve(process.cwd(), "out", String(projectId));
L370:   await fs.rm(outputDir, { recursive: true, force: true });
L371:   await fs.mkdir(outputDir, { recursive: true });
L372: 
L373:   let finished = false;
L374:   const finishOnce = async (status: "completed" | "failed", reason?: string) => {
L375:     if (finished) return;
L376:     finished = true;
L377:     const durationMs = Date.now() - startTime;
L378:     const msg = `[Analyzer ${projectId}] Finalized: status=${status} duration=${durationMs}ms${reason ? ` reason=${reason}` : ""}`;
L379:     if (status === "failed") console.error(msg);
L380:     else console.log(msg);
L381:     logEvent(projectId, "finalize", { status, reason, durationMs });
L382:     await storage.updateProjectStatus(projectId, status);
L383:   };
L384: 
L385:   const pythonBin = path.join(process.cwd(), ".pythonlibs/bin/python3");
L386:   if (!existsSync(pythonBin)) {
L387:     logEvent(projectId, "fatal", { reason: "python_not_found", path: pythonBin });
L388:     await finishOnce("failed", "python_not_found");
L389:     return;
L390:   }
L391: 
L392:   const args = ["-m", "server.analyzer.analyzer_cli", "analyze"];
L393: 
L394:   if (mode === "replit") {
L395:     args.push("--replit");
L396:   } else {
L397:     args.push(source);
L398:   }
L399: 
L400:   args.push("--output-dir", outputDir);
L401: 
L402:   const cmd = `${pythonBin} ${args.join(" ")}`;
L403:   console.log(`[Analyzer ${projectId}] Executing: ${cmd}`);
L404:   logEvent(projectId, "spawn", { cmd });
L405: 
L406:   const pythonProcess = spawn(pythonBin, args, {
L407:     cwd: process.cwd(),
L408:     env: { ...process.env },
L409:   });
L410: 
L411:   const timeout = setTimeout(() => {
L412:     if (finished) return;
L413:     console.error(`[Analyzer ${projectId}] Timeout after 10 minutes  killing`);
L414:     pythonProcess.kill("SIGKILL");
L415:     void finishOnce("failed", "timeout_10m");
L416:   }, Number(process.env.ANALYZER_TIMEOUT_MS) || 10 * 60 * 1000);
L417: 
L418:   let stdout = "";
L419:   let stderr = "";
L420: 
L421:   pythonProcess.stdout.on("data", (data) => {
L422:     stdout += data.toString();
L423:     console.log(`[Analyzer ${projectId}]: ${data}`);
L424:   });
L425: 
L426:   pythonProcess.stderr.on("data", (data) => {
L427:     stderr += data.toString();
L428:     console.error(`[Analyzer ${projectId} ERR]: ${data}`);
L429:   });
L430: 
L431:   pythonProcess.on("error", (err) => {
L432:     clearTimeout(timeout);
L433:     console.error(`[Analyzer ${projectId}] Spawn error:`, err);
L434:     logEvent(projectId, "spawn_error", { error: String(err) });
L435:     void finishOnce("failed", "spawn_error");
L436:   });
L437: 
L438:   pythonProcess.on("close", async (code) => {
L439:     clearTimeout(timeout);
L440:     if (finished) return;
L441:     logEvent(projectId, "exit", { code });
L442:     console.log(`[Analyzer ${projectId}] Exited code=${code}`);
L443: 
L444:     if (code === 0) {
L445:       try {
L446:         const requiredArtifacts = ["operate.json", "DOSSIER.md", "claims.json"];
L447:         for (const artifact of requiredArtifacts) {
L448:           if (!existsSync(path.join(outputDir, artifact))) {
L449:             logEvent(projectId, "missing_artifact", { artifact });
L450:             await finishOnce("failed", `missing_artifact:${artifact}`);
L451:             return;
L452:           }
L453:         }
L454: 
L455:         const dossierPath = path.join(outputDir, "DOSSIER.md");
L456:         const claimsPath = path.join(outputDir, "claims.json");
L457:         const howtoPath = path.join(outputDir, "target_howto.json");
L458:         const operatePath = path.join(outputDir, "operate.json");
L459:         const coveragePath = path.join(outputDir, "coverage.json");
L460: 
L461:         const dossier = await fs.readFile(dossierPath, "utf-8").catch(() => "");
L462:         const claims = JSON.parse(await fs.readFile(claimsPath, "utf-8").catch(() => "{}"));
L463:         const howto = JSON.parse(await fs.readFile(howtoPath, "utf-8").catch(() => "{}"));
L464:         let operate: any = null;
L465:         try {
L466:           operate = JSON.parse(await fs.readFile(operatePath, "utf-8"));
L467:         } catch {
L468:           operate = null;
L469:         }
L470:         const coverage = JSON.parse(await fs.readFile(coveragePath, "utf-8").catch(() => "{}"));
L471: 
L472:         await storage.createAnalysis({
L473:           projectId,
L474:           dossier,
L475:           claims,
L476:           howto,
L477:           operate,
L478:           coverage,
L479:           unknowns: howto.unknowns || [],
L480:         });
L481: 
L482:         await finishOnce("completed");
L483:       } catch (err) {
L484:         console.error(`[Analyzer ${projectId}] Error saving results:`, err);
L485:         logEvent(projectId, "save_error", { error: String(err) });
L486:         await finishOnce("failed", "save_error");
L487:       }
L488:     } else {
L489:       logEvent(projectId, "nonzero_exit", { code, stderr: stderr.slice(-500) });
L490:       await finishOnce("failed", `exit_code_${code}`);
L491:     }
L492:   });
L493: }

--- FILE: server/replit_integrations/audio/index.ts ---
L1: export { registerAudioRoutes } from "./routes";
L2: export {
L3:   openai,
L4:   detectAudioFormat,
L5:   convertToWav,
L6:   ensureCompatibleFormat,
L7:   type AudioFormat,
L8:   voiceChat,
L9:   voiceChatStream,
L10:   textToSpeech,
L11:   textToSpeechStream,
L12:   speechToText,
L13:   speechToTextStream,
L14: } from "./client";

--- FILE: server/replit_integrations/audio/client.ts ---
L1: import OpenAI, { toFile } from "openai";
L2: import { Buffer } from "node:buffer";
L3: import { spawn } from "child_process";
L4: import { writeFile, unlink, readFile } from "fs/promises";
L5: import { randomUUID } from "crypto";
L6: import { tmpdir } from "os";
L7: import { join } from "path";
L8: 
L9: export const openai = new OpenAI({
L10:   apiKey: process.env.AI_INTEGRATIONS_OPENAI_API_KEY,
L11:   baseURL: process.env.AI_INTEGRATIONS_OPENAI_BASE_URL,
L12: });
L13: 
L14: export type AudioFormat = "wav" | "mp3" | "webm" | "mp4" | "ogg" | "unknown";
L15: 
L16: /**
L17:  * Detect audio format from buffer magic bytes.
L18:  * Supports: WAV, MP3, WebM (Chrome/Firefox), MP4/M4A/MOV (Safari/iOS), OGG
L19:  */
L20: export function detectAudioFormat(buffer: Buffer): AudioFormat {
L21:   if (buffer.length < 12) return "unknown";
L22: 
L23:   // WAV: RIFF....WAVE
L24:   if (buffer[0] === 0x52 && buffer[1] === 0x49 && buffer[2] === 0x46 && buffer[3] === 0x46) {
L25:     return "wav";
L26:   }
L27:   // WebM: EBML header
L28:   if (buffer[0] === 0x1a && buffer[1] === 0x45 && buffer[2] === 0xdf && buffer[3] === 0xa3) {
L29:     return "webm";
L30:   }
L31:   // MP3: ID3 tag or frame sync
L32:   if (
L33:     (buffer[0] === 0xff && (buffer[1] === 0xfb || buffer[1] === 0xfa || buffer[1] === 0xf3)) ||
L34:     (buffer[0] === 0x49 && buffer[1] === 0x44 && buffer[2] === 0x33)
L35:   ) {
L36:     return "mp3";
L37:   }
L38:   // MP4/M4A/MOV: ....ftyp (Safari/iOS records in these containers)
L39:   if (buffer[4] === 0x66 && buffer[5] === 0x74 && buffer[6] === 0x79 && buffer[7] === 0x70) {
L40:     return "mp4";
L41:   }
L42:   // OGG: OggS
L43:   if (buffer[0] === 0x4f && buffer[1] === 0x67 && buffer[2] === 0x67 && buffer[3] === 0x53) {
L44:     return "ogg";
L45:   }
L46:   return "unknown";
L47: }
L48: 
L49: /**
L50:  * Convert any audio/video format to WAV using ffmpeg.
L51:  * Uses temp files instead of pipes because video containers (MP4/MOV)
L52:  * require seeking to find the audio track.
L53:  */
L54: export async function convertToWav(audioBuffer: Buffer): Promise<Buffer> {
L55:   const inputPath = join(tmpdir(), `input-${randomUUID()}`);
L56:   const outputPath = join(tmpdir(), `output-${randomUUID()}.wav`);
L57: 
L58:   try {
L59:     // Write input to temp file (required for video containers that need seeking)
L60:     await writeFile(inputPath, audioBuffer);
L61: 
L62:     // Run ffmpeg with file paths
L63:     await new Promise<void>((resolve, reject) => {
L64:       const ffmpeg = spawn("ffmpeg", [
L65:         "-i", inputPath,
L66:         "-vn",              // Extract audio only (ignore video track)
L67:         "-f", "wav",
L68:         "-ar", "16000",     // 16kHz sample rate (good for speech)
L69:         "-ac", "1",         // Mono
L70:         "-acodec", "pcm_s16le",
L71:         "-y",               // Overwrite output
L72:         outputPath,
L73:       ]);
L74: 
L75:       ffmpeg.stderr.on("data", () => {}); // Suppress logs
L76:       ffmpeg.on("close", (code) => {
L77:         if (code === 0) resolve();
L78:         else reject(new Error(`ffmpeg exited with code ${code}`));
L79:       });
L80:       ffmpeg.on("error", reject);
L81:     });
L82: 
L83:     // Read converted audio
L84:     return await readFile(outputPath);
L85:   } finally {
L86:     // Clean up temp files
L87:     await unlink(inputPath).catch(() => {});
L88:     await unlink(outputPath).catch(() => {});
L89:   }
L90: }
L91: 
L92: /**
L93:  * Auto-detect and convert audio to OpenAI-compatible format.
L94:  * - WAV/MP3: Pass through (already compatible)
L95:  * - WebM/MP4/OGG: Convert to WAV via ffmpeg
L96:  */
L97: export async function ensureCompatibleFormat(
L98:   audioBuffer: Buffer
L99: ): Promise<{ buffer: Buffer; format: "wav" | "mp3" }> {
L100:   const detected = detectAudioFormat(audioBuffer);
L101:   if (detected === "wav") return { buffer: audioBuffer, format: "wav" };
L102:   if (detected === "mp3") return { buffer: audioBuffer, format: "mp3" };
L103:   // Convert WebM, MP4, OGG, or unknown to WAV
L104:   const wavBuffer = await convertToWav(audioBuffer);
L105:   return { buffer: wavBuffer, format: "wav" };
L106: }
L107: 
L108: /**
L109:  * Voice Chat: User speaks, LLM responds with audio (audio-in, audio-out).
L110:  * Uses gpt-audio model via Replit AI Integrations.
L111:  * Note: Browser records WebM/opus - convert to WAV using ffmpeg before calling this.
L112:  */
L113: export async function voiceChat(
L114:   audioBuffer: Buffer,
L115:   voice: "alloy" | "echo" | "fable" | "onyx" | "nova" | "shimmer" = "alloy",
L116:   inputFormat: "wav" | "mp3" = "wav",
L117:   outputFormat: "wav" | "mp3" = "mp3"
L118: ): Promise<{ transcript: string; audioResponse: Buffer }> {
L119:   const audioBase64 = audioBuffer.toString("base64");
L120:   const response = await openai.chat.completions.create({
L121:     model: "gpt-audio",
L122:     modalities: ["text", "audio"],
L123:     audio: { voice, format: outputFormat },
L124:     messages: [{
L125:       role: "user",
L126:       content: [
L127:         { type: "input_audio", input_audio: { data: audioBase64, format: inputFormat } },
L128:       ],
L129:     }],
L130:   });
L131:   const message = response.choices[0]?.message as any;
L132:   const transcript = message?.audio?.transcript || message?.content || "";
L133:   const audioData = message?.audio?.data ?? "";
L134:   return {
L135:     transcript,
L136:     audioResponse: Buffer.from(audioData, "base64"),
L137:   };
L138: }
L139: 
L140: /**
L141:  * Streaming Voice Chat: For real-time audio responses.
L142:  * Note: Streaming only supports pcm16 output format.
L143:  *
L144:  * @example
L145:  * // Converting browser WebM to WAV before calling:
L146:  * const webmBuffer = Buffer.from(req.body.audio, "base64");
L147:  * const wavBuffer = await convertWebmToWav(webmBuffer);
L148:  * for await (const chunk of voiceChatStream(wavBuffer)) { ... }
L149:  */
L150: export async function voiceChatStream(
L151:   audioBuffer: Buffer,
L152:   voice: "alloy" | "echo" | "fable" | "onyx" | "nova" | "shimmer" = "alloy",
L153:   inputFormat: "wav" | "mp3" = "wav"
L154: ): Promise<AsyncIterable<{ type: "transcript" | "audio"; data: string }>> {
L155:   const audioBase64 = audioBuffer.toString("base64");
L156:   const stream = await openai.chat.completions.create({
L157:     model: "gpt-audio",
L158:     modalities: ["text", "audio"],
L159:     audio: { voice, format: "pcm16" },
L160:     messages: [{
L161:       role: "user",
L162:       content: [
L163:         { type: "input_audio", input_audio: { data: audioBase64, format: inputFormat } },
L164:       ],
L165:     }],
L166:     stream: true,
L167:   });
L168: 
L169:   return (async function* () {
L170:     for await (const chunk of stream) {
L171:       const delta = chunk.choices?.[0]?.delta as any;
L172:       if (!delta) continue;
L173:       if (delta?.audio?.transcript) {
L174:         yield { type: "transcript", data: delta.audio.transcript };
L175:       }
L176:       if (delta?.audio?.data) {
L177:         yield { type: "audio", data: delta.audio.data };
L178:       }
L179:     }
L180:   })();
L181: }
L182: 
L183: /**
L184:  * Text-to-Speech: Converts text to speech verbatim.
L185:  * Uses gpt-audio model via Replit AI Integrations.
L186:  */
L187: export async function textToSpeech(
L188:   text: string,
L189:   voice: "alloy" | "echo" | "fable" | "onyx" | "nova" | "shimmer" = "alloy",
L190:   format: "wav" | "mp3" | "flac" | "opus" | "pcm16" = "wav"
L191: ): Promise<Buffer> {
L192:   const response = await openai.chat.completions.create({
L193:     model: "gpt-audio",
L194:     modalities: ["text", "audio"],
L195:     audio: { voice, format },
L196:     messages: [
L197:       { role: "system", content: "You are an assistant that performs text-to-speech." },
L198:       { role: "user", content: `Repeat the following text verbatim: ${text}` },
L199:     ],
L200:   });
L201:   const audioData = (response.choices[0]?.message as any)?.audio?.data ?? "";
L202:   return Buffer.from(audioData, "base64");
L203: }
L204: 
L205: /**
L206:  * Streaming Text-to-Speech: Converts text to speech with real-time streaming.
L207:  * Uses gpt-audio model via Replit AI Integrations.
L208:  * Note: Streaming only supports pcm16 output format.
L209:  */
L210: export async function textToSpeechStream(
L211:   text: string,
L212:   voice: "alloy" | "echo" | "fable" | "onyx" | "nova" | "shimmer" = "alloy"
L213: ): Promise<AsyncIterable<string>> {
L214:   const stream = await openai.chat.completions.create({
L215:     model: "gpt-audio",
L216:     modalities: ["text", "audio"],
L217:     audio: { voice, format: "pcm16" },
L218:     messages: [
L219:       { role: "system", content: "You are an assistant that performs text-to-speech." },
L220:       { role: "user", content: `Repeat the following text verbatim: ${text}` },
L221:     ],
L222:     stream: true,
L223:   });
L224: 
L225:   return (async function* () {
L226:     for await (const chunk of stream) {
L227:       const delta = chunk.choices?.[0]?.delta as any;
L228:       if (!delta) continue;
L229:       if (delta?.audio?.data) {
L230:         yield delta.audio.data;
L231:       }
L232:     }
L233:   })();
L234: }
L235: 
L236: /**
L237:  * Speech-to-Text: Transcribes audio using dedicated transcription model.
L238:  * Uses gpt-4o-mini-transcribe for accurate transcription.
L239:  */
L240: export async function speechToText(
L241:   audioBuffer: Buffer,
L242:   format: "wav" | "mp3" | "webm" = "wav"
L243: ): Promise<string> {
L244:   const file = await toFile(audioBuffer, `audio.${format}`);
L245:   const response = await openai.audio.transcriptions.create({
L246:     file,
L247:     model: "gpt-4o-mini-transcribe",
L248:   });
L249:   return response.text;
L250: }
L251: 
L252: /**
L253:  * Streaming Speech-to-Text: Transcribes audio with real-time streaming.
L254:  * Uses gpt-4o-mini-transcribe for accurate transcription.
L255:  */
L256: export async function speechToTextStream(
L257:   audioBuffer: Buffer,
L258:   format: "wav" | "mp3" | "webm" = "wav"
L259: ): Promise<AsyncIterable<string>> {
L260:   const file = await toFile(audioBuffer, `audio.${format}`);
L261:   const stream = await openai.audio.transcriptions.create({
L262:     file,
L263:     model: "gpt-4o-mini-transcribe",
L264:     stream: true,
L265:   });
L266: 
L267:   return (async function* () {
L268:     for await (const event of stream) {
L269:       if (event.type === "transcript.text.delta") {
L270:         yield event.delta;
L271:       }
L272:     }
L273:   })();
L274: }

--- FILE: server/replit_integrations/audio/routes.ts ---
L1: import express, { type Express, type Request, type Response } from "express";
L2: import { chatStorage } from "../chat/storage";
L3: import { openai, speechToText, ensureCompatibleFormat } from "./client";
L4: 
L5: // Body parser with 50MB limit for audio payloads
L6: const audioBodyParser = express.json({ limit: "50mb" });
L7: 
L8: export function registerAudioRoutes(app: Express): void {
L9:   // Get all conversations
L10:   app.get("/api/conversations", async (req: Request, res: Response) => {
L11:     try {
L12:       const conversations = await chatStorage.getAllConversations();
L13:       res.json(conversations);
L14:     } catch (error) {
L15:       console.error("Error fetching conversations:", error);
L16:       res.status(500).json({ error: "Failed to fetch conversations" });
L17:     }
L18:   });
L19: 
L20:   // Get single conversation with messages
L21:   app.get("/api/conversations/:id", async (req: Request, res: Response) => {
L22:     try {
L23:       const id = parseInt(req.params.id);
L24:       const conversation = await chatStorage.getConversation(id);
L25:       if (!conversation) {
L26:         return res.status(404).json({ error: "Conversation not found" });
L27:       }
L28:       const messages = await chatStorage.getMessagesByConversation(id);
L29:       res.json({ ...conversation, messages });
L30:     } catch (error) {
L31:       console.error("Error fetching conversation:", error);
L32:       res.status(500).json({ error: "Failed to fetch conversation" });
L33:     }
L34:   });
L35: 
L36:   // Create new conversation
L37:   app.post("/api/conversations", async (req: Request, res: Response) => {
L38:     try {
L39:       const { title } = req.body;
L40:       const conversation = await chatStorage.createConversation(title || "New Chat");
L41:       res.status(201).json(conversation);
L42:     } catch (error) {
L43:       console.error("Error creating conversation:", error);
L44:       res.status(500).json({ error: "Failed to create conversation" });
L45:     }
L46:   });
L47: 
L48:   // Delete conversation
L49:   app.delete("/api/conversations/:id", async (req: Request, res: Response) => {
L50:     try {
L51:       const id = parseInt(req.params.id);
L52:       await chatStorage.deleteConversation(id);
L53:       res.status(204).send();
L54:     } catch (error) {
L55:       console.error("Error deleting conversation:", error);
L56:       res.status(500).json({ error: "Failed to delete conversation" });
L57:     }
L58:   });
L59: 
L60:   // Send voice message and get streaming audio response
L61:   // Auto-detects audio format and converts WebM/MP4/OGG to WAV
L62:   // Uses gpt-4o-mini-transcribe for STT, gpt-audio for voice response
L63:   app.post("/api/conversations/:id/messages", audioBodyParser, async (req: Request, res: Response) => {
L64:     try {
L65:       const conversationId = parseInt(req.params.id);
L66:       const { audio, voice = "alloy" } = req.body;
L67: 
L68:       if (!audio) {
L69:         return res.status(400).json({ error: "Audio data (base64) is required" });
L70:       }
L71: 
L72:       // 1. Auto-detect format and convert to OpenAI-compatible format
L73:       const rawBuffer = Buffer.from(audio, "base64");
L74:       const { buffer: audioBuffer, format: inputFormat } = await ensureCompatibleFormat(rawBuffer);
L75: 
L76:       // 2. Transcribe user audio
L77:       const userTranscript = await speechToText(audioBuffer, inputFormat);
L78: 
L79:       // 3. Save user message
L80:       await chatStorage.createMessage(conversationId, "user", userTranscript);
L81: 
L82:       // 4. Get conversation history
L83:       const existingMessages = await chatStorage.getMessagesByConversation(conversationId);
L84:       const chatHistory = existingMessages.map((m) => ({
L85:         role: m.role as "user" | "assistant",
L86:         content: m.content,
L87:       }));
L88: 
L89:       // 5. Set up SSE
L90:       res.setHeader("Content-Type", "text/event-stream");
L91:       res.setHeader("Cache-Control", "no-cache");
L92:       res.setHeader("Connection", "keep-alive");
L93: 
L94:       res.write(`data: ${JSON.stringify({ type: "user_transcript", data: userTranscript })}\n\n`);
L95: 
L96:       // 6. Stream audio response from gpt-audio
L97:       const stream = await openai.chat.completions.create({
L98:         model: "gpt-audio",
L99:         modalities: ["text", "audio"],
L100:         audio: { voice, format: "pcm16" },
L101:         messages: chatHistory,
L102:         stream: true,
L103:       });
L104: 
L105:       let assistantTranscript = "";
L106: 
L107:       for await (const chunk of stream) {
L108:         const delta = chunk.choices?.[0]?.delta as any;
L109:         if (!delta) continue;
L110: 
L111:         if (delta?.audio?.transcript) {
L112:           assistantTranscript += delta.audio.transcript;
L113:           res.write(`data: ${JSON.stringify({ type: "transcript", data: delta.audio.transcript })}\n\n`);
L114:         }
L115: 
L116:         if (delta?.audio?.data) {
L117:           res.write(`data: ${JSON.stringify({ type: "audio", data: delta.audio.data })}\n\n`);
L118:         }
L119:       }
L120: 
L121:       // 7. Save assistant message
L122:       await chatStorage.createMessage(conversationId, "assistant", assistantTranscript);
L123: 
L124:       res.write(`data: ${JSON.stringify({ type: "done", transcript: assistantTranscript })}\n\n`);
L125:       res.end();
L126:     } catch (error) {
L127:       console.error("Error processing voice message:", error);
L128:       if (res.headersSent) {
L129:         res.write(`data: ${JSON.stringify({ type: "error", error: "Failed to process voice message" })}\n\n`);
L130:         res.end();
L131:       } else {
L132:         res.status(500).json({ error: "Failed to process voice message" });
L133:       }
L134:     }
L135:   });
L136: }

--- FILE: server/replit_integrations/batch/index.ts ---
L1: export {
L2:   batchProcess,
L3:   batchProcessWithSSE,
L4:   isRateLimitError,
L5:   type BatchOptions,
L6: } from "./utils";
L7: 

--- FILE: server/replit_integrations/batch/utils.ts ---
L1: import pLimit from "p-limit";
L2: import pRetry from "p-retry";
L3: 
L4: /**
L5:  * Batch Processing Utilities
L6:  *
L7:  * This module provides a generic batch processing function with built-in
L8:  * rate limiting and automatic retries. Use it for any task that requires
L9:  * processing multiple items through an LLM or external API.
L10:  *
L11:  * USAGE:
L12:  * ```typescript
L13:  * import { batchProcess, isRateLimitError } from "./replit_integrations/batch";
L14:  *
L15:  * const results = await batchProcess(
L16:  *   artworks,
L17:  *   async (artwork) => {
L18:  *     // Your custom LLM logic here
L19:  *     const response = await openai.chat.completions.create({
L20:  *       model: "gpt-5.1",
L21:  *       messages: [{ role: "user", content: `Categorize: ${artwork.name}` }],
L22:  *       response_format: { type: "json_object" },
L23:  *     });
L24:  *     return JSON.parse(response.choices[0]?.message?.content || "{}");
L25:  *   },
L26:  *   { concurrency: 2, retries: 5 }
L27:  * );
L28:  * ```
L29:  */
L30: 
L31: export interface BatchOptions {
L32:   /** Max concurrent requests (default: 2) */
L33:   concurrency?: number;
L34:   /** Max retry attempts for rate limit errors (default: 7) */
L35:   retries?: number;
L36:   /** Initial retry delay in ms (default: 2000) */
L37:   minTimeout?: number;
L38:   /** Max retry delay in ms (default: 128000) */
L39:   maxTimeout?: number;
L40:   /** Callback for progress updates */
L41:   onProgress?: (completed: number, total: number, item: unknown) => void;
L42: }
L43: 
L44: /**
L45:  * Check if an error is a rate limit or quota violation.
L46:  * Use this in custom error handling if needed.
L47:  */
L48: export function isRateLimitError(error: unknown): boolean {
L49:   const errorMsg = error instanceof Error ? error.message : String(error);
L50:   return (
L51:     errorMsg.includes("429") ||
L52:     errorMsg.includes("RATELIMIT_EXCEEDED") ||
L53:     errorMsg.toLowerCase().includes("quota") ||
L54:     errorMsg.toLowerCase().includes("rate limit")
L55:   );
L56: }
L57: 
L58: /**
L59:  * Process items in batches with rate limiting and automatic retries.
L60:  *
L61:  * @param items - Array of items to process
L62:  * @param processor - Async function to process each item (write your LLM logic here)
L63:  * @param options - Concurrency and retry settings
L64:  * @returns Promise resolving to array of results in the same order as input
L65:  *
L66:  * @example
L67:  * // Process CSV artwork data with custom categorization
L68:  * const categorized = await batchProcess(
L69:  *   csvRows,
L70:  *   async (row) => {
L71:  *     const response = await openai.chat.completions.create({
L72:  *       model: "gpt-5.1", // the newest OpenAI model
L73:  *       messages: [{ role: "user", content: `Categorize artwork: ${row.name}` }],
L74:  *       response_format: { type: "json_object" },
L75:  *     });
L76:  *     return { ...row, category: JSON.parse(response.choices[0]?.message?.content || "{}") };
L77:  *   }
L78:  * );
L79:  */
L80: export async function batchProcess<T, R>(
L81:   items: T[],
L82:   processor: (item: T, index: number) => Promise<R>,
L83:   options: BatchOptions = {}
L84: ): Promise<R[]> {
L85:   const {
L86:     concurrency = 2,
L87:     retries = 7,
L88:     minTimeout = 2000,
L89:     maxTimeout = 128000,
L90:     onProgress,
L91:   } = options;
L92: 
L93:   const limit = pLimit(concurrency);
L94:   let completed = 0;
L95: 
L96:   const promises = items.map((item, index) =>
L97:     limit(() =>
L98:       pRetry(
L99:         async () => {
L100:           try {
L101:             const result = await processor(item, index);
L102:             completed++;
L103:             onProgress?.(completed, items.length, item);
L104:             return result;
L105:           } catch (error: unknown) {
L106:             if (isRateLimitError(error)) {
L107:               throw error; // Rethrow to trigger p-retry
L108:             }
L109:             // For non-rate-limit errors, abort immediately
L110:             throw new pRetry.AbortError(
L111:               error instanceof Error ? error : new Error(String(error))
L112:             );
L113:           }
L114:         },
L115:         { retries, minTimeout, maxTimeout, factor: 2 }
L116:       )
L117:     )
L118:   );
L119: 
L120:   return Promise.all(promises);
L121: }
L122: 
L123: /**
L124:  * Process items sequentially with SSE progress streaming.
L125:  * Use this when you need real-time progress updates to the client.
L126:  *
L127:  * @param items - Array of items to process
L128:  * @param processor - Async function to process each item
L129:  * @param sendEvent - Function to send SSE events to the client
L130:  * @param options - Retry settings (concurrency is always 1 for sequential)
L131:  */
L132: export async function batchProcessWithSSE<T, R>(
L133:   items: T[],
L134:   processor: (item: T, index: number) => Promise<R>,
L135:   sendEvent: (event: { type: string; [key: string]: unknown }) => void,
L136:   options: Omit<BatchOptions, "concurrency" | "onProgress"> = {}
L137: ): Promise<R[]> {
L138:   const { retries = 5, minTimeout = 1000, maxTimeout = 15000 } = options;
L139: 
L140:   sendEvent({ type: "started", total: items.length });
L141: 
L142:   const results: R[] = [];
L143:   let errors = 0;
L144: 
L145:   for (let index = 0; index < items.length; index++) {
L146:     const item = items[index];
L147:     sendEvent({ type: "processing", index, item });
L148: 
L149:     try {
L150:       const result = await pRetry(
L151:         () => processor(item, index),
L152:         {
L153:           retries,
L154:           minTimeout,
L155:           maxTimeout,
L156:           factor: 2,
L157:           onFailedAttempt: (error) => {
L158:             if (!isRateLimitError(error)) {
L159:               throw new pRetry.AbortError(
L160:                 error instanceof Error ? error : new Error(String(error))
L161:               );
L162:             }
L163:           },
L164:         }
L165:       );
L166:       results.push(result);
L167:       sendEvent({ type: "progress", index, result });
L168:     } catch (error) {
L169:       errors++;
L170:       results.push(undefined as R); // Placeholder for failed items
L171:       sendEvent({
L172:         type: "progress",
L173:         index,
L174:         error: error instanceof Error ? error.message : "Processing failed",
L175:       });
L176:     }
L177:   }
L178: 
L179:   sendEvent({ type: "complete", processed: items.length, errors });
L180:   return results;
L181: }
L182: 

--- FILE: server/replit_integrations/chat/routes.ts ---
L1: import type { Express, Request, Response } from "express";
L2: import OpenAI from "openai";
L3: import { chatStorage } from "./storage";
L4: 
L5: const openai = new OpenAI({
L6:   apiKey: process.env.AI_INTEGRATIONS_OPENAI_API_KEY,
L7:   baseURL: process.env.AI_INTEGRATIONS_OPENAI_BASE_URL,
L8: });
L9: 
L10: export function registerChatRoutes(app: Express): void {
L11:   // Get all conversations
L12:   app.get("/api/conversations", async (req: Request, res: Response) => {
L13:     try {
L14:       const conversations = await chatStorage.getAllConversations();
L15:       res.json(conversations);
L16:     } catch (error) {
L17:       console.error("Error fetching conversations:", error);
L18:       res.status(500).json({ error: "Failed to fetch conversations" });
L19:     }
L20:   });
L21: 
L22:   // Get single conversation with messages
L23:   app.get("/api/conversations/:id", async (req: Request, res: Response) => {
L24:     try {
L25:       const id = parseInt(req.params.id);
L26:       const conversation = await chatStorage.getConversation(id);
L27:       if (!conversation) {
L28:         return res.status(404).json({ error: "Conversation not found" });
L29:       }
L30:       const messages = await chatStorage.getMessagesByConversation(id);
L31:       res.json({ ...conversation, messages });
L32:     } catch (error) {
L33:       console.error("Error fetching conversation:", error);
L34:       res.status(500).json({ error: "Failed to fetch conversation" });
L35:     }
L36:   });
L37: 
L38:   // Create new conversation
L39:   app.post("/api/conversations", async (req: Request, res: Response) => {
L40:     try {
L41:       const { title } = req.body;
L42:       const conversation = await chatStorage.createConversation(title || "New Chat");
L43:       res.status(201).json(conversation);
L44:     } catch (error) {
L45:       console.error("Error creating conversation:", error);
L46:       res.status(500).json({ error: "Failed to create conversation" });
L47:     }
L48:   });
L49: 
L50:   // Delete conversation
L51:   app.delete("/api/conversations/:id", async (req: Request, res: Response) => {
L52:     try {
L53:       const id = parseInt(req.params.id);
L54:       await chatStorage.deleteConversation(id);
L55:       res.status(204).send();
L56:     } catch (error) {
L57:       console.error("Error deleting conversation:", error);
L58:       res.status(500).json({ error: "Failed to delete conversation" });
L59:     }
L60:   });
L61: 
L62:   // Send message and get AI response (streaming)
L63:   app.post("/api/conversations/:id/messages", async (req: Request, res: Response) => {
L64:     try {
L65:       const conversationId = parseInt(req.params.id);
L66:       const { content } = req.body;
L67: 
L68:       // Save user message
L69:       await chatStorage.createMessage(conversationId, "user", content);
L70: 
L71:       // Get conversation history for context
L72:       const messages = await chatStorage.getMessagesByConversation(conversationId);
L73:       const chatMessages = messages.map((m) => ({
L74:         role: m.role as "user" | "assistant",
L75:         content: m.content,
L76:       }));
L77: 
L78:       // Set up SSE
L79:       res.setHeader("Content-Type", "text/event-stream");
L80:       res.setHeader("Cache-Control", "no-cache");
L81:       res.setHeader("Connection", "keep-alive");
L82: 
L83:       // Stream response from OpenAI
L84:       const stream = await openai.chat.completions.create({
L85:         model: "gpt-5.1",
L86:         messages: chatMessages,
L87:         stream: true,
L88:         max_completion_tokens: 8192,
L89:       });
L90: 
L91:       let fullResponse = "";
L92: 
L93:       for await (const chunk of stream) {
L94:         const content = chunk.choices[0]?.delta?.content || "";
L95:         if (content) {
L96:           fullResponse += content;
L97:           res.write(`data: ${JSON.stringify({ content })}\n\n`);
L98:         }
L99:       }
L100: 
L101:       // Save assistant message
L102:       await chatStorage.createMessage(conversationId, "assistant", fullResponse);
L103: 
L104:       res.write(`data: ${JSON.stringify({ done: true })}\n\n`);
L105:       res.end();
L106:     } catch (error) {
L107:       console.error("Error sending message:", error);
L108:       // Check if headers already sent (SSE streaming started)
L109:       if (res.headersSent) {
L110:         res.write(`data: ${JSON.stringify({ error: "Failed to send message" })}\n\n`);
L111:         res.end();
L112:       } else {
L113:         res.status(500).json({ error: "Failed to send message" });
L114:       }
L115:     }
L116:   });
L117: }
L118: 

--- FILE: server/replit_integrations/chat/storage.ts ---
L1: import { db } from "../../db";
L2: import { conversations, messages } from "@shared/schema";
L3: import { eq, desc } from "drizzle-orm";
L4: 
L5: export interface IChatStorage {
L6:   getConversation(id: number): Promise<typeof conversations.$inferSelect | undefined>;
L7:   getAllConversations(): Promise<(typeof conversations.$inferSelect)[]>;
L8:   createConversation(title: string): Promise<typeof conversations.$inferSelect>;
L9:   deleteConversation(id: number): Promise<void>;
L10:   getMessagesByConversation(conversationId: number): Promise<(typeof messages.$inferSelect)[]>;
L11:   createMessage(conversationId: number, role: string, content: string): Promise<typeof messages.$inferSelect>;
L12: }
L13: 
L14: export const chatStorage: IChatStorage = {
L15:   async getConversation(id: number) {
L16:     const [conversation] = await db.select().from(conversations).where(eq(conversations.id, id));
L17:     return conversation;
L18:   },
L19: 
L20:   async getAllConversations() {
L21:     return db.select().from(conversations).orderBy(desc(conversations.createdAt));
L22:   },
L23: 
L24:   async createConversation(title: string) {
L25:     const [conversation] = await db.insert(conversations).values({ title }).returning();
L26:     return conversation;
L27:   },
L28: 
L29:   async deleteConversation(id: number) {
L30:     await db.delete(messages).where(eq(messages.conversationId, id));
L31:     await db.delete(conversations).where(eq(conversations.id, id));
L32:   },
L33: 
L34:   async getMessagesByConversation(conversationId: number) {
L35:     return db.select().from(messages).where(eq(messages.conversationId, conversationId)).orderBy(messages.createdAt);
L36:   },
L37: 
L38:   async createMessage(conversationId: number, role: string, content: string) {
L39:     const [message] = await db.insert(messages).values({ conversationId, role, content }).returning();
L40:     return message;
L41:   },
L42: };
L43: 

--- FILE: server/replit_integrations/chat/index.ts ---
L1: export { registerChatRoutes } from "./routes";
L2: export { chatStorage, type IChatStorage } from "./storage";
L3: 

--- FILE: server/replit_integrations/image/index.ts ---
L1: export { registerImageRoutes } from "./routes";
L2: export { openai, generateImageBuffer, editImages } from "./client";
L3: 
